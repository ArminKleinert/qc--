
\input{../config/macros.tex}

% l2h substitution ast AST
% l2h substitution rtl RTL
% l2h substitution noweb NOWEB
% l2h substitution qcc QC--
% l2h substitution C C--
% l2h substitution PAL C--
% l2h substitution pal C--
% l2h substitution asdl ASDL
% l2h substitution ocaml OCaml
% l2h substitution forall forall
% l2h macro module 1 <a href="#$1.html"><tt>#1.nw</tt></a>

% ------------------------------------------------------------------  
\section{Lexical Analysis}\label{sec:scanner}
% ------------------------------------------------------------------  

The scanner for lexical analysis is generated from a specification for
\ocaml~Lex. 

The generated scanner keeps track of its current position in its
input stream by counting the bytes it consumes.  In order to maintain
the more useful information of the current line and column in the
input we maintain some state in a source map which maps input stream
positions to a file name, line number, column number triple.  The
source map is passed as a parameter [[map]] into the scanner.

The first action of the parser is to place a sync point into the
source map.  This guarantees that every position in the input can be
maped to a location.  The fist character is always in line 1 and
column 1 in [[file]].

Whenever the scanner encounters a newline character it places a new
sync point for the following character into the source map.

<<scan.mli>>=
val scan : Srcmap.map -> Lexing.lexbuf -> Parse.token
val tok2str : Parse.token -> string
<<scan.mll>>=
{
    <<prolog>>
}

<<prolog>>=
module P = Parse    (* tokens are defined here *)
module E = Error

let nl lexbuf map =
    let next = (Lexing.lexeme_start lexbuf) + 1     in
        Srcmap.nl map next
    
@ The tab character is one byte long, but moves the cursor additional
$x$ positions to the right.  The number $x$ of virtual spaces depends
on the column $c$ of the tab:

            $$x = 7 - (c~\textrm{mod}~8)$$ 

Whenever the scanner encounters a tab character it calls the [[tab]]
function to place a sync point into the source map.  We currently
ignore tabs by not placing a sync point in the [[map]].  Sync points
are explained in section \ref{srcmap} about source code position
tracking.

<<prolog>>=
let tab lexbuf map = ()
        
@ The current location can be obtained by passing the current position
to [[Srcmap.loc]]:

<<prolog>>=
let location lexbuf map =
    Srcmap.location map (Lexing.lexeme_start lexbuf)
     
let error lexbuf map msg = Error.error msg

@ We define some helpers; [[get]] returns the matched string and is
quite intuitive when called as [[get lexbuf]].

<<prolog>>=
let get         = Lexing.lexeme
let getchar     = Lexing.lexeme_char
let strlen      = String.length
let pos_start   = Lexing.lexeme_start
let pos_end     = Lexing.lexeme_end

@ Some lexemes contain data that we like to extract.  Here is a
substring extraction function (inspired by Python's [[slice]]) that
makes this easy.  The parameters [[start]] and [[stop]] denote which
part of [[str]] should be extracted; negative numbers can be used to
reference the starting point from the end of the string rather than
the beginning.  It is best to think about the [[start]] and [[stop]]
indices as pointing between the characters; some examples makes this
clear:

\begin{quote}
\begin{verbatim}
          h  e  l  l  o  _  w  o  r  l  d
        0  1  2  3  4  5  6  7  8  9  10 11
     -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1  0

    substr 0 0 "hello world"            ;; - : string = "hello world"
    substr 0 1 "hello world"            ;; - : string = "h"
    substr 0 (-1) "hello world"         ;; - : string = "hello worl"
    substr (-3) (-1) "hello world"      ;; - : string = "rl"
    substr (0) (3) "hello world"        ;; - : string = "hel"
\end{verbatim}
\end{quote}

<<prolog>>=
let substr start stop str = 
    let start = if start <  0 then String.length str + start else start in
    let stop  = if stop  <= 0 then String.length str + stop  else stop  in
        String.sub str start (stop - start)
@

All keywords are stored in a hash table that maps them to tokens;
[[keyword s]] tries to lookup [[s]] in the table of keywords and
returns the matching token or raises [[Not_found]].  Keywords are not
directly encoded into the automaton of the scanner because this is
notorious for overflowing the tables of the automaton's
implementation.

<<prolog>>=
let keywords    = Hashtbl.create 127
let keyword s   = Hashtbl.find keywords s

let _ = Array.iter (fun (str,tok) -> Hashtbl.add keywords str tok)
    [|("aborts"         , P.ABORTS)
    ; ("align"          , P.ALIGN)
    ; ("aligned"        , P.ALIGNED)
    ; ("also"           , P.ALSO)
    ; ("as"             , P.AS)
    ; ("big"            , P.BIG)
    ; ("byteorder"      , P.BYTEORDER)
    ; ("case"           , P.CASE)
    ; ("const"          , P.CONST)
    ; ("continuation"   , P.CONTINUATION)
    ; ("cut"            , P.CUT)
    ; ("cuts"           , P.CUTS)
    ; ("else"           , P.ELSE)
    ; ("equal"          , P.EQUAL)
    ; ("export"         , P.EXPORT)
    ; ("foreign"        , P.FOREIGN)
    ; ("goto"           , P.GOTO)
    ; ("if"             , P.IF)
    ; ("import"         , P.IMPORT)
    ; ("invariant"      , P.INVARIANT)
    ; ("jump"           , P.JUMP)
    ; ("little"         , P.LITTLE)
    ; ("memsize"        , P.MEMSIZE)
    ; ("pragma"         , P.PRAGMA)
    ; ("register"       , P.REGISTER)
    ; ("return"         , P.RETURN)
    ; ("returns"        , P.RETURNS)
    ; ("section"        , P.SECTION)
    ; ("semi"           , P.SEMI)
    ; ("span"           , P.SPAN)
    ; ("stackdata"      , P.STACKDATA)
    ; ("switch"         , P.SWITCH)
    ; ("target"         , P.TARGET)
    ; ("targets"        , P.TARGETS)
    ; ("to"             , P.TO)
    ; ("typedef"        , P.TYPEDEF)
    ; ("unicode"        , P.UNICODE)
    ; ("unwinds"        , P.UNWINDS)

    ; ("float"          , P.FLOATREPR)
    ; ("charset"        , P.CHARSET)
    ; ("pointersize"    , P.PTRSIZE)
    ; ("wordsize"       , P.WRDSIZE)

    |]
@

Literals (integer, floating point, character) are stored as
[[Bits.bits]] in the abstract syntax. This is not quite right as
explained in the definition of the abstract syntax \module{ast}. Below
are conversion functions that take strings as arguments and returns a
[[Bits.bits]] value using the maximum width [[Bits.maxwidth]]. The
\emph{type} of a literal, i.e.~its width, is a seperate from the width
of the internal size of the bit vector. A bitvector of width 64 can hold
an integer of type [[bits32]] (but not vice versa). For the types of
expressions see the \module{expcheck} module.

<<prolog>>=
let str2bits f str =
    try f str Bits.maxwidth with
    | Bits.Size     -> E.error "literal too large for this implementation"
    | Bits.Overflow -> assert false (* can't happen - we use maxwidth *)

let stri2bits str = str2bits Bits.of_stringi str
let strf2bits str = str2bits Bits.of_stringf str
let strc2bits str = str2bits Bits.of_stringc str 
@

% ------------------------------------------------------------------  
\subsection{Declarations for Regular Expressions}
% ------------------------------------------------------------------  
<<scan.mll>>=

let digit       = ['0'-'9']
let octal       = ['0'-'7']
let hex         = ['0'-'9' 'A'-'F' 'a'-'f']

let printable   = [' '-'~']     (* add 8bit chars *)
let alpha       = ['a'-'z' 'A'-'Z']
let misc        = ['.' '_' '$' '@']

let escape      = ['\\' '\'' '"' 'a' 'b' 'f' 'n' 'r' 't' '?' ]

let sign        = ['+' '-']
let nat         = digit+
let int         = '0' ['x' 'X'] hex+
                | digit+        (* includes octal *)
let frac        = nat '.' nat
let exp         = ['e''E'] sign? nat
let float       = frac exp? 
                | nat exp

let cxxcomment  = "//" [^ '\n']*
                
let id          = (alpha | misc) (alpha | misc | digit)*
let ws          = [' ' '\012' '\r']  (* SP FF CR *)
let nl          = '\n'          
let tab         = '\t'

@
% ------------------------------------------------------------------  
\subsection{The Main Lexer}
% ------------------------------------------------------------------  

The entry point for the lexer is the [[scan]] function. When a
source code map [[map]] is applied to it, it becomes a lexer
function suitable for a parser generated by \textsc{ocamllex}.

<<scanner entry point>>=
let scan map lexbuf =
    token lexbuf map
@

When the lexer is called is enters the [[token]] context where it
recognizes all keywords and simple tokens.  For complex tokens like
strings or comments it branches into special contexts.

<<scan.mll>>=
rule token = parse
    eof         { fun map -> P.EOF          }
  | ws+         { fun map -> token lexbuf map }
  | tab         { fun map -> tab lexbuf map; token lexbuf map }
  | nl          { fun map -> nl lexbuf map ; token lexbuf map }
  | ws* '#'     { fun map -> line lexbuf map 0; token lexbuf map }
  | ";"         { fun map -> P.SEMI         }
  | ":"         { fun map -> P.COLON        }
  | "::"        { fun map -> P.CCOLON       }
  | ","         { fun map -> P.COMMA        }
  | ".."        { fun map -> P.DOTDOT       }
  
  | "("         { fun map -> P.LPAREN       }
  | ")"         { fun map -> P.RPAREN       }
  | "{"         { fun map -> P.LBRACE       }
  | "}"         { fun map -> P.RBRACE       }
  | "["         { fun map -> P.LBRACKET     }
  | "]"         { fun map -> P.RBRACKET     }
  | "%%"        { fun map -> P.PPERCENT     }

  
  | "="         { fun map -> P.EQUAL        }
  

  (* infix/prefix operators *)
  
  | "+"         { fun map -> P.PLUS(get lexbuf)      }
  | "-"         { fun map -> P.MINUS(get lexbuf)     }
  | "*"         { fun map -> P.STAR(get lexbuf)      }
  | "/"         { fun map -> P.SLASH(get lexbuf)     }
  | "%"         { fun map -> P.PERCENT(get lexbuf)   }
  | "@>>"        { fun map -> P.GGREATER(get lexbuf)  }
  | "@<<"        { fun map -> P.LLESS(get lexbuf)     }
  | "&"         { fun map -> P.AMPERSAND(get lexbuf) }
  | "|"         { fun map -> P.BAR(get lexbuf)       }
  | "^"         { fun map -> P.CARET(get lexbuf)     }
  | "~"         { fun map -> P.TILDE(get lexbuf)     }
  | "=="        { fun map -> P.EEQ(get lexbuf)       }
  | "!="        { fun map -> P.NEQ(get lexbuf)       }
  | "<"         { fun map -> P.LT(get lexbuf)        }
  | "<="        { fun map -> P.LEQ(get lexbuf)       }
  | ">"         { fun map -> P.GT(get lexbuf)        }
  | ">="        { fun map -> P.GEQ(get lexbuf)       }

  | "`" id "`"  { fun map -> P.INFIXOP(substr 1 (-1) (get lexbuf)) }
              
  | "bits" nat  { fun map -> 
                  let s = substr 4 0 (get lexbuf) in
                  P.BITSn (int_of_string s)
                }
@

An identifier is an [[ID]] unless it is a reserved word.  When it is
the reserved word [[pragma]] the [[PRAGMA]] token is returned by
[[keyword]] and we switch to the special [[pragma1]] context. 

<<scan.mll>>=
  | id          { fun map ->  
                  let s  = get lexbuf in 
                  let k  = try keyword s with Not_found -> P.ID s in
                    if k = P.PRAGMA then pragma1 lexbuf map else k  
                } 
  | '%' id      { fun map ->
                  let s = substr 1 0 (get lexbuf)
                  in P.PRIMOP(s)
                }
  | float       { fun map -> P.FLT (strf2bits (get lexbuf)) }
  | int         { fun map -> P.INT (stri2bits (get lexbuf)) }
  
  | "/*"        { fun map -> comment1 lexbuf map }
  | cxxcomment  { fun map -> token lexbuf map (* skip comment *) }
  
  | "\""        { fun map -> string  lexbuf map (Buffer.create 80) }
  | "'"         { fun map -> character lexbuf map } 
 
  | _           { fun map -> error lexbuf map "illegal character" }
@

% ------------------------------------------------------------------  
\subsection{Character Literals}
% ------------------------------------------------------------------  

The interpretation functions for escaped characters are not yet
written. Currently the string representation is returned.

<<scan.mll>>=
and character = parse
    printable      "'"          { fun map -> 
                                  let s = substr 0 (-1) (get lexbuf) in
                                  P.CHAR  (strc2bits s)
                                }
  
  | '\\' escape    "'"          { fun map -> 
                                  let s = substr 0 (-1) (get lexbuf) in
                                  P.CHAR  (strc2bits s)
                                }

  
  | '\\' ['x' 'X'] hex+ "'"     { fun map -> 
                                  let s = substr 0 (-1) (get lexbuf) in
                                  P.CHAR  (strc2bits s)
                                }
                                  
  | _                           { fun map ->
                                  error lexbuf map "illegal character literal" 
                                }

@
% ------------------------------------------------------------------  
\subsection{Comments}
% ------------------------------------------------------------------  

Comments in C-- originally could nest but for compatibility with the C
preprocessor this feature was droped.  Since it is impossible to
include the character sequence [[*/]] in a C comment C$++$ style
comments are additionally accepted:  a comment starts with [//] and
goes up to the end of the line.  The latter comments are not
implemented with a separate scanner context but inlined.
 
<<scan.mll>>=
and comment1 = parse
    eof                         { fun map ->
                                  error lexbuf map "unterminated comment" 
                                }
  | [^ '*' '\n' '\t' '/']+      { fun map ->
                                  comment1 lexbuf map
                                }
  | nl                          { fun map ->
                                  nl lexbuf map; comment1 lexbuf map 
                                }
  | nl '#'                      { fun map -> 
                                  line lexbuf map 0; comment1 lexbuf map
                                }
  
  | tab                         { fun map -> 
                                  tab lexbuf map; comment1 lexbuf map
                                }
  | "*"                         { fun map ->
                                  comment1 lexbuf map
                                }
  | "*/"                        { fun map ->
                                  token lexbuf map 
                                }
  | _                           { fun map ->
                                  comment1 lexbuf map 
                                }
@

% ------------------------------------------------------------------  
\subsection{Strings}
% ------------------------------------------------------------------  

Escapes do not yet work; calls to the decoding function must be added 
where [[XXX]] marked.

<<scan.mll>>=
and string = parse
    eof                         { fun map buf -> 
                                  error lexbuf map "unterminated string" 
                                }
  | "\""                        { fun map buf -> P.STR (Buffer.contents buf) 
                                  (* we are done *)
                                }

  | [^ '\000'-'\031'
       '\128'-'\255'
       '"' '\\' ]+              { fun map buf ->
                                  let s    = get lexbuf              in
                                  ( Buffer.add_string buf s
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\' octal+                 { fun map buf -> 
                                  let s = substr 1 0 (get lexbuf) in
                                  ( Buffer.add_string buf s (* XXX *)
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\' ['x' 'X'] hex+         { fun map buf -> 
                                  let s = substr 2 0 (get lexbuf) in
                                  ( Buffer.add_string buf s (* XXX *)
                                  ; string lexbuf map buf
                                  )
                                }  
  | '\\' escape                 { fun map buf ->
                                  let c    = getchar lexbuf 1       in
                                  ( Buffer.add_char buf c   (* XXX *)
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\' _                      { fun map buf ->
                                  error lexbuf map "illegal character escape"
                                }
  | _                           { fun map buf ->
                                  error lexbuf map "illegal character in string"
                                }

@

% ------------------------------------------------------------------  
\subsection{Pragmas}
% ------------------------------------------------------------------ 

Pragmas are special because the work on the lexical as well as on the
grammatical level: 

\begin{itemize}
\item A \textit{known} pragma is handled like a keyword -- normal
      scanning and parsing resumes.

\item An \textit{unknown} pragma is skipped by the scanner. 
\end{itemize}

The split personality of pragmas leads to a scanner that uses a
sequence of three scanner contexts to simulate some parsing in case an
unknown pragma must be skipped over.

To decide whether a pragma is known we look at its
\textit{target}---the identifier following the [[pragma]] keyword.
While looking for the identifier white space is skipped and special
characters are noticed. It is an error when no identifier is found.

When an identifier is found but it is not in the [[keywords]] table
the pragma must be skipped by the parser.  This requires to find the
body of the pragma that is enclosed by curly brackets.  Looking for
the opening bracket takes place in the [[pragma2]] scanner context.

<<scan.mll>>=
and pragma1 = parse
    eof                 { fun map -> P.EOF }
  | ws+                 { fun map -> pragma1 lexbuf map }
  | tab                 { fun map -> tab lexbuf map; pragma1 lexbuf map }
  | nl                  { fun map -> nl lexbuf map;  pragma1 lexbuf map } 
  | id                  { fun map -> 
                          let s  = get lexbuf in 
                          try ( match keyword s with 
                              | _     -> pragma2 lexbuf map s
                              )
                          with Not_found -> pragma2 lexbuf map s
                        }
  | _                   { fun map -> 
                          error lexbuf map "id for pragma expected" 
                        }


and pragma2 = parse
    eof                 { fun map id -> 
                          error lexbuf map "pragma body expected" 
                        }
  | ws+                 { fun map id -> pragma2 lexbuf map id }
  | tab                 { fun map id -> tab lexbuf map; pragma2 lexbuf map id}
  | nl                  { fun map id -> nl  lexbuf map; pragma2 lexbuf map id}
  | '{'                 { fun map id -> 
                          pragma3 lexbuf map 0 
                        }
  | _                   { fun map id -> 
                          error lexbuf map "pragma body expected" 
                        }
@

It is an error when the opening bracket is not found. Once it is
found the body of the pragma is skipped over in context [[pragma3]]. A
body of a pragma must contain legal \C~tokens. We don't have to care
for the details but must consider only the following cases:

\begin{itemize}
\item The curly brackets may nest. So we keep a [[level]] to find the
      matching closing bracket.

\item Brackets inside of strings literals, character literals, and
      comments are not considered. Each of these are handled in their
      own scanner contexts.
\end{itemize}


<<scan.mll>>=
and pragma3 = parse
    eof                         { fun map level ->
                                  error lexbuf map "unterminated pragma" 
                                }
  | [^ '{' '}'  '\n' '\t' 
       '/' '\'' '"']+           { fun map level ->
                                  pragma3 lexbuf map level
                                }
  | nl                          { fun map level ->
                                  nl lexbuf map
                                ; pragma3 lexbuf map level 
                                }
  | tab                         { fun map level -> 
                                  tab lexbuf map; pragma3 lexbuf map level
                                }
  | '{'                         { fun map level -> 
                                  pragma3 lexbuf map (level+1)
                                }
  | '}'                         { fun map level ->
                                  if   level = 0 
                                  then token lexbuf map
                                  else pragma3 lexbuf map (level-1)
                                }
  | cxxcomment                  { fun map -> pragma3 lexbuf map (* ignore *) } 
  | "/*"                        { fun map level -> 
                                  ignore (comment1 lexbuf map) 
                                ; pragma3 lexbuf map level
                                }
  | "\""                        { fun map level -> 
                                  ignore (string lexbuf map (Buffer.create 80))
                                ; pragma3 lexbuf map level
                                }
  | "'"                         { fun map level -> 
                                  ignore (character lexbuf map)
                                ; pragma3 lexbuf map level
                                }
  
  | _                           { fun map level ->
                                  pragma3 lexbuf map level 
                                }
@

% ------------------------------------------------------------------ 
\subsubsection{C-Style Line Pragma}
% ------------------------------------------------------------------ 

Although not intended it is likely that \C~is used with the C
preprocessor.  It emits directives to link a line in its output to a
another source file.  In principle the [[line]] pragma is intended for
this task.  However, the C preprocessor can not emit this pragmas
instead and thus we provide support for the C preprocessor directive.

The implementation is a new scanner context that requires that the
line directive is matched by the following regular expression (in the
syntax used by \ocaml-Lex and using expressions defined above):

\begin{center}
[[ws* '#' ws+ nat '"'[^ '"']*'"' ws* '\n']]
\end{center}

Note that {\small ANSI/ISO} C allows whitespace before and after the
[[#]] character. Leading whitespace has already been recognized at this
point.

The meaning of a line directive
\texttt{\#}~\textit{line}~\texttt{"}file\texttt{"} is that the
\textit{following} line is on line \textit{line} in file
\textit{file}.  The implementation links the current line to
$\textit{line}-1$ in \textit{file} by placing a sync point.

This implementation does not check the syntax but just recognizes
different tokens. It returns when it finds a string and relies on the
fact that the line number must come first.

<<scan.mll>>=
and line = parse 
    eof                 { fun map l ->
                          error lexbuf map "unterminated line directive" 
                        }
  | ws+                 { fun map l -> line lexbuf map l }
  | tab                 { fun map l -> line lexbuf map l }
  | '"'                 { fun map l ->
                          let buf      = Buffer.create 80 in
                          let _        = string lexbuf map buf in
                          let file     = Buffer.contents buf in
                          let pos      = Lexing.lexeme_start lexbuf in
                          let location = file, l-1, 1 in
                                ( Srcmap.sync map pos location
                                ; () (* return *)
                                )
                        }
  | nat                 { fun map l -> 
                          
                          (* inline'ing the l' expression caused an
                          int_of_string failure with ocamlopt *)
                          
                          let l' = int_of_string (get lexbuf)
                          in  line lexbuf map l'
                        }
  | id                  { fun map l ->
                          line lexbuf map l
                        }
  | _                   { fun map l -> 
                          error lexbuf map 
                          "illegal character in line directive"
                        }
@




<<scan.mll>>=

{   (* start of epilog *)
    <<scanner entry point>>
@

% ------------------------------------------------------------------  
\subsection{Debugging the Scanner}
% ------------------------------------------------------------------  

In case of an parse error the problem may be actually caused by the
scanner.  For debugging we define a function [[tok2str]] that turns a
token (as defined in [[parse.mli]]) into a string.  This is used below
to define a function that reports the stream of all tokens for a file
together with their positions.

<<scan.mll>>=
    let tok2str = function

    | P.ABORTS            -> "ABORTS"
    | P.ALIGN             -> "ALIGN"
    | P.ALIGNED           -> "ALIGNED"
    | P.ALSO              -> "ALSO"
    | P.AS                -> "AS"
    | P.COLON             -> "COLON"
    | P.CCOLON            -> "CCOLON"
    | P.COMMA             -> "COMMA"
    | P.CONST             -> "CONST"
    | P.CONTINUATION      -> "CONTINUATION"
    | P.CUT               -> "CUT"
    | P.CUTS              -> "CUTS"
    | P.ELSE              -> "ELSE"
    | P.EOF               -> "EOF"
    | P.EQUAL             -> "EQUAL"
    | P.EXPORT            -> "EXPORT"
    | P.FOREIGN           -> "FOREIGN"
    | P.GOTO              -> "GOTO"
    | P.IF                -> "IF"
    | P.IMPORT            -> "IMPORT"
    | P.INVARIANT         -> "INVARIANT"
    | P.JUMP              -> "JUMP"
    | P.LBRACE            -> "LBRACE"
    | P.LBRACKET          -> "LBRACKET"
    | P.LPAREN            -> "LPAREN"
    | P.PPERCENT          -> "PPERCENT"
    | P.PRAGMA            -> "PRAGMA"
    | P.RBRACE            -> "RBRACE"
    | P.RBRACKET          -> "RBRACKET"
    | P.REGISTER          -> "REGISTER"
    | P.RETURN            -> "RETURN"
    | P.RETURNS           -> "RETURNS"
    | P.RPAREN            -> "RPAREN"
    | P.SECTION           -> "SECTION"
    | P.SEMI              -> "SEMI"
    | P.SPAN              -> "SPAN"
    | P.STACKDATA         -> "STACKDATA"
    | P.TARGETS           -> "TARGETS"
    | P.TO                -> "TO"
    | P.UNICODE           -> "UNICODE"
    | P.UNWINDS           -> "UNWINDS"

    | P.TYPEDEF           -> "TYPEDEF" 
    | P.MEMSIZE           -> "MEMSIZE"
    | P.BYTEORDER         -> "BYTEORDER"
    | P.LITTLE            -> "LITTLE"
    | P.BIG               -> "BIG"
    | P.CASE              -> "CASE"
    | P.DEFAULT           -> "DEFAULT"
    | P.TARGET            -> "TARGET"
    | P.DOTDOT            -> "DOTDOT"
    | P.SWITCH            -> "SWITCH"

    | P.WRDSIZE           -> "WORSIZE"
    | P.PTRSIZE           -> "POINTERSIZE"
    | P.FLOATREPR         -> "FLOAT"
    | P.CHARSET           -> "CHARSET"
    

    | P.AMPERSAND(s)      -> "AMPERSAND(" ^ s ^ ")"
    | P.BAR(s)            -> "BAR(" ^       s ^ ")"
    | P.CARET(s)          -> "CARET(" ^     s ^ ")"
    | P.EEQ(s)            -> "EEQ(" ^       s ^ ")"
    | P.GEQ(s)            -> "GEQ(" ^       s ^ ")"
    | P.GGREATER(s)       -> "GGREATER(" ^  s ^ ")"
    | P.GT(s)             -> "GT(" ^        s ^ ")"
    | P.LEQ(s)            -> "LEQ(" ^       s ^ ")"
    | P.LLESS(s)          -> "LLESS(" ^     s ^ ")"
    | P.LT(s)             -> "LT(" ^        s ^ ")"
    | P.MINUS(s)          -> "MINUS(" ^     s ^ ")"
    | P.NEQ(s)            -> "NEQ(" ^       s ^ ")"
    | P.PERCENT(s)        -> "PERCENT(" ^   s ^ ")"
    | P.PLUS(s)           -> "PLUS(" ^      s ^ ")"
    | P.SLASH(s)          -> "SLASH(" ^     s ^ ")"
    | P.STAR(s)           -> "STAR(" ^      s ^ ")"
    | P.TILDE(s)          -> "TILDE(" ^     s ^ ")"
    | P.UMINUS(s)         -> "UMINUS" ^     s ^ ")"
    
    
    | P.ID(s)             -> "ID(" ^        s                  ^ ")"
    | P.STR(s)            -> "STR(" ^       s                  ^ ")"
    | P.INFIXOP(s)        -> "INFIXOP(" ^   s                  ^ ")"
    | P.PRIMOP(s)         -> "PRIMOP(" ^    s                  ^ ")"
    | P.INT(i)            -> "INT(" ^  Bits.to_string None   i ^ ")"
    | P.FLT(f)            -> "FLT(" ^  Bits.to_string None   f ^ ")"
    | P.CHAR(c)           -> "CHAR(" ^ Bits.to_string None   c ^ ")"
    | P.BITSn(i)          -> "BITSn(" ^ string_of_int i        ^ ")"

} (* end of epilog *)
@


% ------------------------------------------------------------------  
\section{Grammatical Analysis}\label{sec:parser}
% ------------------------------------------------------------------  

The parser reads a token stream created by the scanner (module
[[Scan]]) and return the abstract syntax of the input, as defined by
module [[Ast]]. 

<<parse.mly>>=
%{
    module A = Ast
    module E = Error

    <<helper functions>>            
%}
@     

[[p]] returns the region for the left hand symbol in the current
production.  A region (of type [[int * int]] contains the position of
the first character character of the symbol in input stream, and the
position of the first character after the symbol.  These regions are
attached to important nodes in the abstract syntax.  The function
[[pn]] returns the region for symbol [[n]] on the right hand side,
where the leftmost symbol has index 1.

<<helper functions>>=
let p  ()  = (Parsing.symbol_start (), Parsing.symbol_end())
let pn n   = (Parsing.rhs_start n, Parsing.rhs_end n)
let px ()  = (Parsing.symbol_start ())

let rev    = List.rev

<<helper functions>>=
let mkRegs v (hint,ty,regs) =
    let r (id,reg) = (v, hint, ty, id, reg) 
    in
        List.map r regs
<<helper functions>>=
let mkTypedefs ty names =
    List.map (fun n -> A.Typedef(n,ty)) names
@            

The [[[bits2int]] function takes a [[bits]] value and returns its integer
value; additionally it takes care of possible overflows.

<<helper functions>>=
let bits2int b = 
    try
        Bits.to_int b
    with
        Bits.Overflow -> E.error "Constant exceeds implementation limits"
@

<<parse.mly>>=
%token ABORTS ALIGN ALIGNED ALSO AS AMPERSAND BIG BYTEORDER CASE COLON CCOLON
%token COMMA CONST CONTINUATION CUT CUTS DEFAULT DOTDOT ELSE EOF EQUAL
%token EXPORT FOREIGN GOTO IF IMPORT INFIXOP INVARIANT JUMP LBRACE
%token LBRACKET LITTLE LPAREN MEMSIZE PPERCENT RBRACE RBRACKET REGISTER
%token RETURN RETURNS RPAREN SECTION SEMI SPAN STACKDATA SWITCH TARGET
%token TARGETS TO TYPEDEF UNICODE UNWINDS
%token WRDSIZE PTRSIZE FLOATREPR CHARSET

/* pragmas */

%token PRAGMA

<<parse.mly>>=
/* infix and prefix operators */

%token <string> EEQ NEQ LT LEQ GT GEQ
%token <string> BAR                      
%token <string> CARET                    
%token <string> AMPERSAND                
%token <string> LLESS GGREATER           
%token <string> PLUS MINUS               
%token <string> PERCENT STAR SLASH       
%token <string> TILDE UMINUS                    
%token <string> INFIXOP
%token <string> PRIMOP 

%token <string>         ID
%token <string>         STR
%token <int>            BITSn
%token <Bits.bits>      INT
%token <Bits.bits>      FLT
%token <Bits.bits>      CHAR
@

The precedence of tokens from lowest to highest precedence.

<<parse.mly>>=
/* lvalue conflict resolution */
%right      ID
%right      LBRACKET

%nonassoc   INFIXOP
%nonassoc   EEQ NEQ LT LEQ GT GEQ
%left       BAR                      
%left       CARET                    
%left       AMPERSAND                
%left       LLESS GGREATER           
%left       PLUS MINUS               
%left       PERCENT STAR SLASH       
%right      TILDE UMINUS

%start program
%type <Ast.program>program

%%

program     :   toplevels                      { rev $1}

toplevels   :   toplevels toplevelAt           { $2::$1 }
            |   /**/                           { []     }
<<parse.mly>>=
toplevelAt  :   toplevel                       { A.ToplevelAt($1,p())       }
toplevel    :   SECTION STR LBRACE sections RBRACE  { A.Section($2, rev $4) }
            |   procedure                      { A.TopProcedure($1)         }
            |   declAt                         { A.TopDecl($1)              }
<<parse.mly>>=
sections    :   sections sectionAt             { $2 :: $1 }
            |   /**/                           { []       }

sectionAt   :   section                        { A.SectionAt($1,p()) }
section     :   procedure                      { A.Procedure($1)     }
            |   datum                          { A.Datum($1)         }
            |   span                           { A.SSpan($1)         }
            |   declAt                         { A.Decl($1)          }

<<parse.mly>>=
declAt      :   decl                           { A.DeclAt($1,p()) }   
decl        :   INVARIANT REGISTER registers SEMI
                    { A.Registers(mkRegs A.Invariant $3) }
            |   INVARIANT /*----*/ registers SEMI
                    { A.Registers(mkRegs A.Invariant $2) }
            |   /*-----*/ REGISTER registers SEMI
                    { A.Registers(mkRegs A.Variant $2)   }
            |   /*-----*/ /*----*/ registers SEMI
                    { A.Registers(mkRegs A.Variant $1)   }

            |   EXPORT    exports  SEMI        { A.Export(None, $2)    }
            |   EXPORT ty exports  SEMI        { A.Export(Some $2, $3) }
            |   IMPORT ty imports  SEMI        { A.Import($2,$3)           }
            |   CONST     ID EQUAL exprAt SEMI { A.Const(None,$2,$4)       }
            |   CONST  ty ID EQUAL exprAt SEMI { A.Const(Some $2,$3,$5)    }
            |   TYPEDEF ty names SEMI          { A.Typedef($2,rev $3)      }
            |   TARGET properties SEMI         { A.Target(rev $2)          }
<<parse.mly>>=
property    :   MEMSIZE INT                    { A.Memsize(bits2int $2)      }
            |   BYTEORDER BIG                  { A.ByteorderBig              }
            |   BYTEORDER LITTLE               { A.ByteorderLittle           }
            |   FLOATREPR STR                  { A.FloatRepr $2              }
            |   CHARSET STR                    { A.Charset $2                }
            |   PTRSIZE INT                    { A.PointerSize (bits2int $2) }
            |   WRDSIZE INT                    { A.WordSize (bits2int $2)    }

<<parse.mly>>=
properties  :   properties property            { $2 :: $1 }
            |   /**/                           { []       }
<<parse.mly>>=
span        :   SPAN exprAt expr
                LBRACE sections RBRACE         { $2, $3, rev $5 }
<<parse.mly>>=
datumAt     :   datum                          { A.DatumAt($1,p()) }
datum       :   ID COLON                       { A.Label $1 }
            |   ALIGN INT SEMI                 { A.Align (bits2int $2) }
            |   tyAt size initAt SEMI          { A.MemDecl($1,$2,Some $3)}
            |   tyAt size        SEMI          { A.MemDecl($1,$2,None)}
            |   tyAt      initAt SEMI          { A.MemDecl($1,A.NoSize,Some $2)}
            |   tyAt             SEMI          { A.MemDecl($1,A.NoSize,None)}
<<parse.mly>>=
initAt      :   init                           { A.InitAt($1,p()) }
init        :   LBRACE   exprs RBRACE          { A.InitExprs($2)  }
            |   STR                            { A.InitStr($1)    }
            |   string16                       { A.InitUStr($1)   }
<<parse.mly>>=
registers   :   STR    tyAt regs               { Some $1, $2, rev $3 }
            |   STR    tyAt regs COMMA         { Some $1, $2, rev $3 }
            |          tyAt regs COMMA         { None   , $1, rev $2 }
            |          tyAt regs               { None   , $1, rev $2 }

regs        :   regs COMMA ID STR              { ($3, Some $4)::$1 }
            |   regs COMMA ID                  { ($3, None   )::$1 }
            |   ID STR                         { [($1,Some $2)]    }
            |   ID                             { [($1,None   )]    }

<<parse.mly>>=
size        :   LBRACKET exprAt RBRACKET       { A.FixSize($2) }
            |   LBRACKET       RBRACKET        { A.DynSize     }

procedure   :   conv ID frmls body             {  $1, $2, $3, $4 }
            |        ID frmls body             {None, $1, $2, $3 }

body        :   LBRACE body0 RBRACE            { rev $2 }

body0       :   body0 bodyAt                   { $2 :: $1 }
            |   /**/                           { []       }

bodyAt      :   body1                          { A.BodyAt($1,p()) }
body1       :   declAt                         { A.DeclBody $1    }
            |   stackdecl                      { A.DataBody $1    }
            |   stmtAt                         { A.StmtBody $1    }

frmls       :   LPAREN  formals RPAREN         { $2 }
            |   LPAREN          RPAREN         { [] }
actls       :   LPAREN  actuals RPAREN         { $2 }
            |   LPAREN          RPAREN         { [] }

formals     :   formals_ optcomma              { rev $1   }
formals_    :   formals_ COMMA formal          { $3 :: $1 }
            |   formal                         { [$1]     }

actuals     :   actuals_ optcomma              { rev $1   }
actuals_    :   actuals_ COMMA actual          { $3 :: $1 }
            |   actual                         { [$1]     }

formal      :   STR INVARIANT REGISTER tyAt ID { Some $1, A.Invariant, $4, $5}
            |   STR           REGISTER tyAt ID { Some $1, A.Variant  , $3, $4}
            |       INVARIANT REGISTER tyAt ID { None   , A.Invariant, $3, $4}
            |                 REGISTER tyAt ID { None   , A.Variant  , $2, $3}
            |   STR INVARIANT          tyAt ID { Some $1, A.Invariant, $3, $4}
            |   STR                    tyAt ID { Some $1, A.Variant  , $2, $3}
            |       INVARIANT          tyAt ID { None   , A.Invariant, $2, $3}
            |                          tyAt ID { None   , A.Variant  , $1, $2}

cformal     :   STR ID                         { Some $1, $2 }
            |       ID                         { None   , $1 }

cformals    :   cformals_ optcomma             { rev $1   }
            |   /**/      optcomma             { []       }
cformals_   :   cformals_ COMMA cformal        { $3 :: $1 }
            |   cformal                        { [$1]     }

actual      :   STR exprAt                     { Some $1, $2 }
            |       exprAt                     { None   , $1 }

<<parse.mly>>=
stackdecl   :   STACKDATA LBRACE data RBRACE   { rev $3 }

data        :   data  datumAt                  { $2 :: $1 }
            |   /**/                           { []       }

conv        :   FOREIGN STR                    { Some $2 }

aligned     :   ALIGNED INT                    { Some (bits2int $2) }

flowAt      :   flow                           { A.FlowAt($1,p()) }
flow        :   ALSO CUTS     TO names         { A.CutsTo($4)     }
            |   ALSO UNWINDS  TO names         { A.UnwindsTo($4)  }
            |   ALSO RETURNS  TO names         { A.ReturnsTo($4)  }
            |   ALSO ABORTS                    { A.Aborts         }

flows       :   flows flowAt                   { $2 :: $1 }
            |   /**/                           { []       }

targets     :   TARGETS names                  { $2 }
            |   /**/                           { [] }
@
The grammar uses [[lvalue]] not only at the left hand side of
assignments but also as part of expressions where they denote the
values of registers and memory.  The introduction of hints for
registers (implemented as [[opstr ID]] or similar) has lead to serious
reduce/reduce conflicts caused by the use of [[lvalueAt]] in
[[sexpr]].  One way of getting rid of them was to split the original
[[lvalueAt]] into [[lvalueAt0]] and [[lvalueAt]]:  [[lvalueAt0]] does
not include [[STR ID]] which is not needed for [[sexpr]].

<<parse.mly>>=
lvalueAt    :   lvalue                         { A.LValueAt($1,p()) } 
lvalue      :   lvalue0                        { $1 } 
            |   STR ID                         { A.Var(Some $1,$2) } 
            
<<parse.mly>>=
lvalueAt0   :   lvalue0                                { A.LValueAt($1,p()) }
lvalue0     :   ID                                     { A.Var(None, $1)    }
            |   sty   LBRACKET exprAt aligned RBRACKET { A.Mem($1,$3,$4)    }
            |   sty   LBRACKET exprAt         RBRACKET { A.Mem($1,$3,None)  }
            |   ID    LBRACKET exprAt aligned RBRACKET
                        { A.Mem(A.AliasTy($1),$3,$4)                        }
            |   ID    LBRACKET exprAt         RBRACKET
                        { A.Mem(A.AliasTy($1),$3,None)                      }

lvalues     :   lvalues_ optcomma              { rev $1   }
lvalues_    :   lvalues_ COMMA lvalueAt        { $3 :: $1 }
            |   lvalueAt                       { [$1]     }

tyAt        :   ty                             { A.TyAt($1,p()) }
ty          :   sty                            { $1             }
            |   ID                             { A.AliasTy($1)  }

sty         :   BITSn                          { A.BitsTy($1)     }

returnto    :   LT sexprAt SLASH sexprAt GT    { Some($2,$4) }
            |   /**/                           { None        }
<<parse.mly>>=
stmtAt      :   stmt                           { A.StmtAt($1,p())     }
stmt        :   SEMI                           { A.EmptyStmt          }
            |   ID COLON                       { A.LabelStmt $1       }
            |   SPAN exprAt exprAt body        { A.SpanStmt($2,$3,$4) }
            |   lvalues EQUAL exprs SEMI       
                { A.AssignStmt($1,List.map (fun e -> None,e) $3)  }

            |   lvalues EQUAL conv PPERCENT ID actls flows SEMI
                { A.PrimStmt($1, $3, $5, $6, rev $7) }      
            
            |                 conv PPERCENT ID actls flows SEMI
                { A.PrimStmt([], $1, $3, $4, rev $5) }      
            
            |   lvalues EQUAL conv expr actls targets flows SEMI
                { A.CallStmt($1, $3, $4, $5, $6, rev $7)  }
            
            |                 conv expr actls targets flows SEMI
                { A.CallStmt([], $1, $2, $3, $4, rev $5)  }
                                          
            |   lvalues EQUAL      PPERCENT ID actls flows SEMI
                { A.PrimStmt($1, None, $4, $5, rev $6)    }
            
            |                      PPERCENT ID actls flows SEMI
                { A.PrimStmt( [], None, $2, $3, rev $4)}
            
            |   lvalues EQUAL      expr actls targets flows SEMI
                { A.CallStmt($1, None, $3, $4, $5, rev $6)}

            |                      expr actls targets flows SEMI
                { A.CallStmt([], None, $1, $2, $3, rev $4)}
 
            |   IF exprAt body                      {A.IfStmt($2,$3,[])}
            |   IF exprAt body  ELSE body           {A.IfStmt($2,$3,$5)}
            |   GOTO exprAt targets SEMI            {A.GotoStmt($2,$3)}
            |   CONTINUATION ID LPAREN cformals RPAREN COLON
                                                    {A.ContStmt($2,$4)}
            |   CUT TO expr actls flows SEMI        {A.CutStmt($3,$4, rev $5)  }
            |   conv JUMP exprAt       targets SEMI {A.JumpStmt($1  ,$3,[],$4) }
            |        JUMP exprAt       targets SEMI {A.JumpStmt(None,$2,[],$3) }
            |   conv JUMP exprAt actls targets SEMI {A.JumpStmt($1  ,$3,$4,$5) }
            |        JUMP exprAt actls targets SEMI {A.JumpStmt(None,$2,$3,$4) }
            |   conv RETURN returnto       SEMI     {A.ReturnStmt($1  ,$3,[])  }
            |        RETURN returnto       SEMI     {A.ReturnStmt(None,$2,[])  }
            |   conv RETURN returnto actls SEMI     {A.ReturnStmt($1  ,$3,$4)  }
            |        RETURN returnto actls SEMI     {A.ReturnStmt(None,$2,$3)  }
            |   SWITCH srange expr LBRACE arms RBRACE  
                        {A.SwitchStmt($2,$3, rev $5)}

<<parse.mly>>=
srange      :   LBRACKET range RBRACKET        {Some $2}
            |   /**/                           {None}

range       :   expr                           {A.Point $1     }
            |   expr DOTDOT expr               {A.Range ($1,$3)}

ranges      :   ranges_                        { rev $1 }
            |   ranges_ COMMA                  { rev $1 }
            |   /**/                           { [] } 

ranges_     :   ranges_ COMMA range            { $3 :: $1 } 
            |   range                          { [$1]     } 

arms        :   arms armAt                     { $2 :: $1  }
            |   /**/                           { []        }

armAt       :   arm                            { A.ArmAt($1,p()) }
arm         :   CASE ranges COLON body         { A.Case($2,$4)   } 

<<parse.mly>>=
sexprAt     :   sexpr                          { A.ExprAt($1, p())    }
sexpr       :   INT                            { A.Int($1, None)      }
            |   INT CCOLON tyAt                { A.Int($1, Some $3)   }
            |   FLT                            { A.Float($1, None)    }
            |   FLT CCOLON tyAt                { A.Float($1, Some $3) }
            |   CHAR                           { A.Char($1, None)     }
            |   CHAR CCOLON tyAt               { A.Char($1, Some $3)  }
            |   lvalueAt0                      { A.Fetch $1           }
            |   PRIMOP actls                   { A.PrimOp($1,$2)      }
<<parse.mly>>=
exprAt      :   expr                           { A.ExprAt($1, p())    }
expr:       |   sexpr                          { $1                   }
            |   LPAREN exprAt RPAREN           { $2                   }

            |   exprAt PLUS       exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt MINUS      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt PERCENT    exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt STAR       exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt SLASH      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LLESS      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GGREATER   exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt CARET      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt BAR        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt AMPERSAND  exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt EEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt NEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LT         exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GT         exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt INFIXOP    exprAt       { A.BinOp($1,$2,$3) }
            |   TILDE  exprAt  %prec TILDE     { A.UnOp($1,$2)     }
           /*
            |   MINUS exprAt %prec UMINUS      { A.UnOp($1,$2)     }
            */

exprs       :   exprs_ optcomma                { rev $1   }
exprs_      :   exprs_ COMMA exprAt            { $3 :: $1 }
            |   exprAt                         { [$1]     }
<<parse.mly>>=
imports     :   imports_ optcomma              { rev $1           }
imports_    :   imports_ COMMA STR AS ID       { (Some $3,$5)::$1 }
            |   imports_ COMMA        ID       { (None   ,$3)::$1 } 
            |   STR AS ID                      { [Some $1,$3]     }
            |   ID                             { [None   ,$1]     }

exports     :   exports_ optcomma              { rev $1           }
exports_    :   exports_ COMMA ID AS STR       { ($3,Some $5)::$1 }
            |   exports_ COMMA ID              { ($3,None)::$1    }
            |   ID AS STR                      { [$1,Some $3]     }
            |   ID                             { [$1,None]        }

names       :   names_ optcomma                { rev $1 }
names_      :   names_ COMMA optstr ID         { $4:: $1}
            |   optstr ID                      { [$2]   }

optcomma    :   COMMA                          {}
            |   /**/                           {}

optstr      :   STR                            { Some $1 }
            |   /**/                           { None    }
string16    :   UNICODE LPAREN STR RPAREN      { $3 }
@


