
% l2h substitution C C--
% l2h substitution asdl ASDL
% l2h substitution ocaml OCaml

% ------------------------------------------------------------------  
\section{Lexical Analysis}\label{sec:scanner}
% ------------------------------------------------------------------  

The scanner for lexical analysis is generated from a specification for
\ocaml~Lex. 

The generated scanner keeps track of its current position in its
input stream by counting the bytes it consumes.  In order to maintain
the more useful information of the current line and column in the
input we maintain some state in a source map which maps input stream
positions to a file name, line number, column number triple.  The
source map is passed as a parameter [[map]] into the scanner.

The first action of the parser is to place a sync point into the
source map.  This guarantees that every position in the input can be
maped to a location.  The fist character is always in line 1 and
column 1 in [[file]].

Whenever the scanner encounters a newline character it places a new
sync point for the following character into the source map.

<<scan.mll>>=
{
    open Parse      (* tokens are defined here *)


    let nl lexbuf map =
        let next = (Lexing.lexeme_start lexbuf) + 1     in
            Srcmap.nl map next

@ The tab character is one byte long, but moves the cursor additional
$x$ positions to the right.  The number $x$ of virtual spaces depends
on the column $c$ of the tab:

            $$x = 7 - (c~\textrm{mod}~8)$$ 

Whenever the scanner encounters a tab character it calls the [[tab]]
function to place a sync point into the source map. We currently
ignore tabs by not placing a sync point.

<<scan.mll>>=
    let tab lexbuf map = ()
        
@ The current location can be obtained by passing the current position
to [[Srcmap.location]]:

<<scan.mll>>= 

    let location lexbuf map =
        Srcmap.location map (Lexing.lexeme_start lexbuf)
     
    let error lexbuf map msg = 
        let point = (map, Lexing.lexeme_start lexbuf) in
            Error.errorExn point [msg]

@ We define some helpers; [[get]] returns the matched string and is
quite intuitive when called as [[get lexbuf]].

<<scan.mll>>=
    let get         = Lexing.lexeme
    let getchar     = Lexing.lexeme_char
    let strlen      = String.length
    let pos_start   = Lexing.lexeme_start
    let pos_end     = Lexing.lexeme_end

@ Some lexems contain data that we like to extract.  Here is a
substring extraction function (inspired by Python's [[slice]]) that
makes this easy.  The parameters [[start]] and [[stop]] denote which
part of [[str]] should be extracted; negative numbers can be used to
reference the starting point from the end of the string rather than
the beginning.  It is best to think about the [[start]] and [[stop]]
indices as pointing between the characters; some examples makes this
clear:

<<substr example>>=
          h  e  l  l  o  _  w  o  r  l  d
        0  1  2  3  4  5  6  7  8  9  10 11
     -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1  0

    substr 0 0 "hello world"            ;; - : string = "hello world"
    substr 0 1 "hello world"            ;; - : string = "h"
    substr 0 (-1) "hello world"         ;; - : string = "hello worl"
    substr (-3) (-1) "hello world"      ;; - : string = "rl"
    substr (0) (3) "hello world"        ;; - : string = "hel"

<<scan.mll>>=
    let substr start stop str = 
        let start = if start <  0 then String.length str + start else start in
        let stop  = if stop  <= 0 then String.length str + stop  else stop  in
            String.sub str start (stop - start)

@ Strings and character literals may contain escaped characters like in
[["this \n"]] example; [[escape]] decodes them.


<<scan.mll>>=
    let escape = function
        | 't'   -> '\t'
        | 'n'   -> '\n'
        | 'b'   -> '\b'
        | 'r'   -> '\r'
        |  x    ->  x  (* default *)

@ All keywords are stored in a hash table that maps them to tokens;
[[keyword s]] tries to lookup [[s]] in the table of keywords and
returns the matching token or raises [[Not_found]]. 

<<scan.mll>>=
    let keywords    = Hashtbl.create 127
    let keyword s   = Hashtbl.find keywords s

    let _ = Array.iter (fun (str,tok) -> Hashtbl.add keywords str tok)
        [|("aborts"         , ABORTS)
        ; ("align"          , ALIGN)
        ; ("aligned"        , ALIGNED)
        ; ("also"           , ALSO)
        ; ("const"          , CONST)
        ; ("continuation"   , CONTINUATION)
        ; ("cut"            , CUT)
        ; ("cuts"           , CUTS)
        ; ("else"           , ELSE)
        ; ("equal"          , EQUAL)
        ; ("export"         , EXPORT)
        ; ("foreign"        , FOREIGN)
        ; ("goto"           , GOTO)
        ; ("if"             , IF)
        ; ("import"         , IMPORT)
        ; ("invariant"      , INVARIANT)
        ; ("jump"           , JUMP)
        ; ("pragma"         , PRAGMA)
        ; ("register"       , REGISTER)
        ; ("return"         , RETURN)
        ; ("returns"        , RETURNS)
        ; ("section"        , SECTION)
        ; ("semi"           , SEMI)
        ; ("span"           , SPAN)
        ; ("stackdata"      , STACKDATA)
        ; ("targets"        , TARGETS)
        ; ("to"             , TO)
        ; ("unicode"        , UNICODE)
        ; ("unwinds"        , UNWINDS)

        (* pragmas *)

        ; ("line"           , LINE_)
        |]

} (* end of prolog *)

@
% ------------------------------------------------------------------  
\subsection{Declarations for Regular Expressions}
% ------------------------------------------------------------------  
<<scan.mll>>=

let digit       = ['0'-'9']
let octal       = ['0'-'7']
let decchar     = digit digit digit

let printable   = [' '-'~']     (* add 8bit chars *)
let alpha       = ['a'-'z' 'A'-'Z' '_']

let escape      = ['\\' '\'' '"' 'n' 't' 'b' 'r']

let sign        = ['+' '-']
let nat         = digit+
let frac        = nat? '.' nat
let exp         = ['e''E'] sign? nat
let float       = frac exp? 
                | nat exp


let id          = alpha (alpha | digit | '.')*
let ws          = [' ' '\b']
let nl          = '\n'
let tab         = '\t'
let flag        = '{' alpha+ '}' 

@
% ------------------------------------------------------------------  
\subsection{The Main Lexer}
% ------------------------------------------------------------------  

The entry point for the lexer is the [[scan]] function. When a
source code map [[map]] is applied to it, it becomes a lexer
function suitable for a parser generated by \textsc{ocamllex}.

<<scanner entry point>>=
let scan map lexbuf =
    token lexbuf map

@ When the lexer is called is enters the [[token]] context where it
recognizes all keywords and simple tokens. For complex tokens like
strings or comments it branches into special contexts.

<<scan.mll>>=

rule token = parse
    eof         { fun map -> EOF          }
  | ws+         { fun map -> token lexbuf map }
  | tab         { fun map -> tab lexbuf map; token lexbuf map }
  | nl          { fun map -> nl lexbuf map ; token lexbuf map }

  | ";"         { fun map -> SEMI         }
  | ":"         { fun map -> COLON        }
  | ","         { fun map -> COMMA        }

  | "("         { fun map -> LPAREN       }
  | ")"         { fun map -> RPAREN       }
  | "{"         { fun map -> LBRACE       }
  | "}"         { fun map -> RBRACE       }
  | "["         { fun map -> LBRACKET     }
  | "]"         { fun map -> RBRACKET     }
  | "%%"        { fun map -> PPERCENT     }

  | "="         { fun map -> EQUAL        }
  

  (* infix/prefix operators *)
  
  | "+"         { fun map -> PLUS(get lexbuf)      }
  | "-"         { fun map -> MINUS(get lexbuf)     }
  | "*"         { fun map -> STAR(get lexbuf)      }
  | "/"         { fun map -> SLASH(get lexbuf)     }
  | "%"         { fun map -> PERCENT(get lexbuf)   }
  | ">>"        { fun map -> GGREATER(get lexbuf)  }
  | "<<"        { fun map -> LLESS(get lexbuf)     }
  | "&"         { fun map -> AMPERSAND(get lexbuf) }
  | "|"         { fun map -> BAR(get lexbuf)       }
  | "^"         { fun map -> CARET(get lexbuf)     }
  | "~"         { fun map -> TILDE(get lexbuf)     }
  | "=="        { fun map -> EEQ(get lexbuf)       }
  | "!="        { fun map -> NEQ(get lexbuf)       }
  | "<"         { fun map -> LT(get lexbuf)        }
  | "<="        { fun map -> LEQ(get lexbuf)       }
  | ">"         { fun map -> GT(get lexbuf)        }
  | ">="        { fun map -> GEQ(get lexbuf)       }

              
  | "bits" nat  { fun map -> 
                  let s = substr 4 0 (get lexbuf) in
                  BITSn (int_of_string s)
                }
  | "float" nat { fun map -> 
                  let s = substr 5 0 (get lexbuf) in
                  FLOATn (int_of_string s)
                }

@ An identifier is an [[ID]] unless it is a reserved word.  When it is
the reserved word [[pragma]] the [[PRAGMA]] token is returned by
[[keyword]] and we switch to the special [[pragma1]] context. 

<<scan.mll>>=
  | id          { fun map ->  
                  let s  = get lexbuf in 
                  let k  = try keyword s with Not_found -> ID s in
                    if k = PRAGMA then pragma1 lexbuf map else k  
                } 
  | float       { fun map -> FLT (get lexbuf) }
  | nat         { fun map -> INT (get lexbuf) }

  
  | "/*"        { fun map -> comment lexbuf map 0 }
  | "\""        { fun map -> string  lexbuf map (Buffer.create 80) }
  | "'"         { fun map -> character lexbuf map } 
 
  | _           { fun map -> error lexbuf map "illegal character" }

@
% ------------------------------------------------------------------  
\subsection{Character Literals}
% ------------------------------------------------------------------  
<<scan.mll>>=

and character = parse
    printable      "'"          { fun map -> CHAR (get lexbuf) }
  | '\\' escape    "'"          { fun map -> 
                                  let c = (getchar lexbuf 2) in
                                  CHAR (String.make 1 (escape c))
                                }
  | '\\' decchar   "'"          { fun map -> 
                                  let s = substr 2 (-1) (get lexbuf) in
                                  let c = Char.chr (int_of_string s) in
                                  CHAR  (String.make 1 c)
                                }
  | '\\' _                      { fun map -> 
                                  error lexbuf map "illegal character escape" 
                                }
  | _                           { fun map ->
                                  error lexbuf map "illegal character constant" 
                                }

@
% ------------------------------------------------------------------  
\subsection{Comments}
% ------------------------------------------------------------------  
<<scan.mll>>=

and comment = parse
    eof                         { fun map level ->
                                  error lexbuf map "unterminated comment" 
                                }
  | [^ '*' '\n' '\t' '/']+      { fun map level ->
                                  comment lexbuf map level
                                }
  | nl                          { fun map level ->
                                  nl lexbuf map; comment lexbuf map level 
                                }
  | tab                         { fun map level -> 
                                  tab lexbuf map; comment lexbuf map level
                                }
  | "/*"                        { fun map level -> 
                                  comment lexbuf map (level+1)
                                }
  | "*"+                        { fun map level ->
                                  comment lexbuf map level
                                }
  | "*/"                        { fun map level ->
                                  if   level = 0 
                                  then token lexbuf map
                                  else comment lexbuf map (level-1)
                                }
  | _                           { fun map level ->
                                  comment lexbuf map level 
                                }

@
% ------------------------------------------------------------------  
\subsection{Strings}
% ------------------------------------------------------------------  
<<scan.mll>>=

and string = parse
    eof                         { fun map buf -> 
                                  error lexbuf map "unterminated string" 
                                }
  | "\""                        { fun map buf -> STR (Buffer.contents buf) }
  | [^ '\000'-'\031'
       '\128'-'\255'
       '"' '\\' ]+              { fun map buf ->
                                  let s    = get lexbuf              in
                                  ( Buffer.add_string buf s
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\' escape                 { fun map buf ->
                                  let c    = getchar lexbuf 1       in
                                  let c'   = escape c               in
                                  ( Buffer.add_char buf c'
                                  ; string lexbuf map buf
                                  )
                                }
  
  | '\\' decchar                { fun map buf ->
                                  let s    = substr 1 0 (get lexbuf    ) in
                                  let c    = Char.chr (int_of_string s ) in
                                  ( Buffer.add_char buf c
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\' _                      { fun map buf ->
                                  error lexbuf map "illegal character escape"
                                }
  | _                           { fun map buf ->
                                  error lexbuf map "illegal character in string"
                                }

@

% ------------------------------------------------------------------  
\subsection{Pragmas}
% ------------------------------------------------------------------ 

Pragmas are special because the work on the lexical as well as on the
grammatical level: 

\begin{itemize}
\item A \textit{known} pragma is handled like a keyword -- normal
      scanning and parsing resumes.

\item An \textit{unknown} pragma is skipped by the scanner. 
\end{itemize}

The split personality of pragmas leads to a scanner that uses a
sequence of three scanner contexts to simulate some parsing in case an
unknown pragma must be skipped over.

To decide whether a pragma is known we look at its
\textit{target}---the identifier following the [[pragma]] keyword.
While looking for the identifier white space is skipped and special
characters are noticed. It is an error when no identifier is found.

When an identifier is found but it is not in the [[keywords]] table
the pragma must be skipped by the parser.  This requires to find the
body of the pragma that is enclosed by curly brackets.  Looking for
the opening bracket takes place in the [[pragma2]] scanner context.

<<scan.mll>>=
 
and pragma1 = parse
    eof                 { fun map -> EOF }
  | ws+                 { fun map -> pragma1 lexbuf map }
  | tab                 { fun map -> tab lexbuf map; pragma1 lexbuf map }
  | nl                  { fun map -> nl lexbuf map;  pragma1 lexbuf map } 
  | id                  { fun map -> 
                          let s  = get lexbuf in 
                          try ( match keyword s with 
                              | LINE_ -> LINE(map)
                              | _     -> pragma2 lexbuf map
                              )
                          with Not_found -> pragma2 lexbuf map 
                        }
  | _                   { fun map -> 
                          error lexbuf map "id for pragma expected" 
                        }


and pragma2 = parse
    eof                 { fun map -> 
                          error lexbuf map "pragma body expected" 
                        }
  | ws+                 { fun map -> pragma2 lexbuf map }
  | tab                 { fun map -> tab lexbuf map; pragma2 lexbuf map }
  | nl                  { fun map -> nl  lexbuf map; pragma2 lexbuf map }
  | '{'                 { fun map -> pragma3 lexbuf map 0 }
  | _                   { fun map -> 
                          error lexbuf map "pragma body expected" 
                        }

@ It is an error when the opening bracket is not found. Once it is
found the body of the pragma is skipped over in context [[pragma3]]. A
body of a pragma must contain legal \C~tokens. We don't have to care
for the details but must consider only the following cases:

\begin{itemize}
\item The curly brackets may nest. So we keep a [[level]] to find the
      matching closing bracket.

\item Brackets inside of strings literals, character literals, and
      comments are not considered. Each of these are handled in their
      own scanner contexts.
\end{itemize}


<<scan.mll>>=

and pragma3 = parse
    eof                         { fun map level ->
                                  error lexbuf map "unterminated pragma" 
                                }
  | [^ '{' '}'  '\n' '\t' 
       '/' '\'' '"']+           { fun map level ->
                                  pragma3 lexbuf map level
                                }
  | nl                          { fun map level ->
                                  nl lexbuf map
                                ; pragma3 lexbuf map level 
                                }
  | tab                         { fun map level -> 
                                  tab lexbuf map; pragma3 lexbuf map level
                                }
  | '{'                         { fun map level -> 
                                  pragma3 lexbuf map (level+1)
                                }
  | '}'                         { fun map level ->
                                  if   level = 0 
                                  then token lexbuf map
                                  else pragma3 lexbuf map (level-1)
                                }
  | "/*"                        { fun map level -> 
                                  ignore (comment lexbuf map 0)
                                ; pragma3 lexbuf map level
                                }
  | "\""                        { fun map level -> 
                                  ignore (string lexbuf map (Buffer.create 80))
                                ; pragma3 lexbuf map level
                                }
  | "'"                         { fun map level -> 
                                  ignore (character lexbuf map)
                                ; pragma3 lexbuf map level
                                }
  
  | _                           { fun map level ->
                                  pragma3 lexbuf map level 
                                }

{ (* start of epilog *)
                               
<<scanner entry point>>
                                
@

% ------------------------------------------------------------------  
\subsection{Debugging the Scanner}
% ------------------------------------------------------------------  

In case of an parse error the problem may be actually caused by the
scanner.  For debugging we define a function [[tok2str]] that turns a
token (as defined in [[parse.mli]]) into a string.  This is used in
the [[Main]] module to define a function that reports the stream of
all tokens for a file together with their positions.

<<scan.mll>>=

    let tok2str = function

    | ABORTS            -> "ABORTS"
    | ALIGN             -> "ALIGN"
    | ALIGNED           -> "ALIGNED"
    | ALSO              -> "ALSO"
    | COLON             -> "COLON"
    | COMMA             -> "COMMA"
    | CONST             -> "CONST"
    | CONTINUATION      -> "CONTINUATION"
    | CUT               -> "CUT"
    | CUTS              -> "CUTS"
    | ELSE              -> "ELSE"
    | EOF               -> "EOF"
    | EQUAL             -> "EQUAL"
    | EXPORT            -> "EXPORT"
    | FOREIGN           -> "FOREIGN"
    | GOTO              -> "GOTO"
    | IF                -> "IF"
    | IMPORT            -> "IMPORT"
    | INVARIANT         -> "INVARIANT"
    | JUMP              -> "JUMP"
    | LBRACE            -> "LBRACE"
    | LBRACKET          -> "LBRACKET"
    | LPAREN            -> "LPAREN"
    | PPERCENT          -> "PPERCENT"
    | PRAGMA            -> "PRAGMA"
    | RBRACE            -> "RBRACE"
    | RBRACKET          -> "RBRACKET"
    | REGISTER          -> "REGISTER"
    | RETURN            -> "RETURN"
    | RETURNS           -> "RETURNS"
    | RPAREN            -> "RPAREN"
    | SECTION           -> "SECTION"
    | SEMI              -> "SEMI"
    | SPAN              -> "SPAN"
    | STACKDATA         -> "STACKDATA"
    | TARGETS           -> "TARGETS"
    | TO                -> "TO"
    | UNICODE           -> "UNICODE"
    | UNWINDS           -> "UNWINDS"

    (* pragmas *)

    | LINE(_)           -> "LINE" 
    | LINE_             -> "LINE" 

    | AMPERSAND(s)      -> "AMPERSAND(" ^ s ^ ")"
    | BAR(s)            -> "BAR(" ^       s ^ ")"
    | CARET(s)          -> "CARET(" ^     s ^ ")"
    | EEQ(s)            -> "EEQ(" ^       s ^ ")"
    | GEQ(s)            -> "GEQ(" ^       s ^ ")"
    | GGREATER(s)       -> "GGREATER(" ^  s ^ ")"
    | GT(s)             -> "GT(" ^        s ^ ")"
    | LEQ(s)            -> "LEQ(" ^       s ^ ")"
    | LLESS(s)          -> "LLESS(" ^     s ^ ")"
    | LT(s)             -> "LT(" ^        s ^ ")"
    | MINUS(s)          -> "MINUS(" ^     s ^ ")"
    | NEQ(s)            -> "NEQ(" ^       s ^ ")"
    | PERCENT(s)        -> "PERCENT(" ^   s ^ ")"
    | PLUS(s)           -> "PLUS(" ^      s ^ ")"
    | SLASH(s)          -> "SLASH(" ^     s ^ ")"
    | STAR(s)           -> "STAR(" ^      s ^ ")"
    | TILDE(s)          -> "TILDE(" ^     s ^ ")"
    
    | ID(s)             -> "ID(" ^ s                     ^ ")"
    | STR(s)            -> "STR(" ^ s                    ^ ")"
    | INT(i)            -> "INT(" ^ i                    ^ ")"
    | FLT(f)            -> "FLT(" ^ f                    ^ ")"
    | BITSn(i)          -> "BITSn(" ^ string_of_int i    ^ ")"
    | FLOATn(i)         -> "FLOATSn(" ^ string_of_int i  ^ ")"
    | CHAR(c)           -> "CHAR(" ^ c                   ^ ")"
    
}

@


% ------------------------------------------------------------------  
\section{Grammatical Analysis}\label{sec:parser}
% ------------------------------------------------------------------  

The parser reads a token stream created by the scanner (module
[[Scan]]) and return the abstract syntax of the input, as defined by
module [[Ast]]. 

<<parse.mly>>=
/* Do not edit; edit $RCSfile$ insted.  */

%{

open Ast
open List

let error pos msg = Error.parseExn pos msg

let mkRegs v (ty,regs) =
    let r (id,hint) = (v, ty, id, hint) 
    in
        map r regs

@ Multiple assignments are defined as a list of pairs in the abstract syntax
but two lists in the concrete syntax. The [[assign]] function implements
the classic [[zip]] function to join them into a list of pairs.

<<parse.mly>>= 

let assign pos left right = 
    let rec loop = function 
        | [], []            -> []
        | [], rr            -> error pos "too few lvalues in assignment"
        | ll, []            -> error pos "too many lvalues in assignment"
        | (l::ll),(r::rr)   -> (l,r)::loop (ll,rr) 
    in
        loop (left,right)
     
@ [[p]] returns the region for the left hand symbol in the current
production.  A region (of type [[int * int]] contains the position of
the first character character of the symbol in input stream, and the
position of the first character after the symbol. These regions are
attached to important nodes in the abstract syntax. The function
[[pn]] returns the region for symbol [[n]] on the right hand side,
where the leftmost symbol has index 1.

<<parse.mly>>=

let p  () = (Parsing.symbol_start (), Parsing.symbol_end())
let pn n  = (Parsing.rhs_start n, Parsing.rhs_end n)
let px () = (Parsing.symbol_start ())
let atoi  = int_of_string
%}

/* keywords, symbols, flags */

%token ABORTS
%token ALIGN
%token ALIGNED
%token ALSO
%token AMPERSAND
%token COLON
%token COMMA
%token CONST
%token CONTINUATION
%token CUT
%token CUTS
%token ELSE
%token EOF
%token EQUAL
%token EXPORT
%token FOREIGN
%token GOTO
%token IF
%token IMPORT
%token INVARIANT
%token JUMP
%token LBRACE
%token LBRACKET
%token LPAREN
%token PPERCENT
%token RBRACE
%token RBRACKET
%token REGISTER
%token RETURN
%token RETURNS
%token RPAREN
%token SECTION
%token SEMI
%token SPAN
%token STACKDATA
%token TARGETS
%token TO
%token UNICODE
%token UNWINDS

/* pragmas */

%token PRAGMA

@ We need two tokens for [[pragma line]]:  [[LINE_]] is only used
inside the scanner while detecting that the [[line]] pragma is known. 
Then [[LINE]] is returned with the current source location map
attached.

<<parse.mly>>= 
%token <Srcmap.map> LINE
%token LINE_

/* infix and prefix operators */

%token <string> EEQ NEQ LT LEQ GT GEQ
%token <string> BAR                      
%token <string> CARET                    
%token <string> AMPERSAND                
%token <string> LLESS GGREATER           
%token <string> PLUS MINUS               
%token <string> PERCENT STAR SLASH       
%token <string> TILDE                    


@ The abstract syntax is defined by an \asdl~specification which does not
provide data types for characters and floating point numbers. For this
reason strings are used to capture the values of the respective literals.

<<parse.mly>>=

%token <string> ID
%token <string> INT
%token <string> FLT
%token <string> CHAR
%token <string> STR
%token <int>    BITSn
%token <int>    FLOATn

/* precedence - from lowest to highest precedence */

%nonassoc   EEQ NEQ LT LEQ GT GEQ
%left       BAR                      
%left       CARET                    
%left       AMPERSAND                
%left       LLESS GGREATER           
%left       PLUS MINUS               
%left       PERCENT STAR SLASH       
%right      TILDE                    

%start program
%type <Ast.program>program

%%

program     :   toplevels                         { rev $1 }

toplevels   :   toplevels toplevelAt              { $2::$1 }
            |   /**/                              { []     }

pragma      :   PRAGMA LBRACE RBRACE              { Pragma } 
            |   line                              { Pragma }

line        :   LINE LBRACE STR INT RBRACE        
                    { let pos = Parsing.rhs_start 1 in
                      let map = $1 in
                        Srcmap.sync map pos ($3,atoi $4,1) 
                    }  
                     
            |   LINE LBRACE STR INT INT RBRACE
                    { let pos = Parsing.rhs_start 1 in
                      let map = $1 in
                        Srcmap.sync map  pos ($3,atoi $4,atoi $5) 
                    }
            
toplevelAt  :   toplevel                          { TopDeclAt($1,p())        }
toplevel    :   IMPORT ty names  SEMI             { Import($2,rev $3)        }
            |   EXPORT    names  SEMI             { Export (None   , rev $2) }
            |   EXPORT ty names  SEMI             { Export (Some $2, rev $3) }
            |   CONST LBRACE constants RBRACE     { Const(rev $3)            }
            |   INVARIANT REGISTER registers SEMI
                    { Registers (mkRegs Invariant $3)                        }
            |   /*-----*/ REGISTER registers SEMI
                    { Registers (mkRegs Variant   $2)                        }
            
            |   SECTION STR LBRACE sections RBRACE { Section($2,rev $4) }
            |   pragma                            { $1                  }


sections    :   sections sectionAt                { $2 :: $1 }
            |   /**/                              { []       }

sectionAt   :   section                           { SectionAt($1,p())         }
section     :   procedure                         { $1                        }
            |   datum                             { Datum($1)                 }
            |   span                              { $1                        }
            |   EXPORT    names  SEMI             { SExport (None   , rev $2) }
            |   EXPORT ty names  SEMI             { SExport (Some $2, rev $3) }

span        :   SPAN exprAt expr 
                LBRACE sections RBRACE            { SSpan($2,$3,rev $5) }

constants   :   constants ID EQUAL exprAt SEMI    { ($2,$4)::$1 }
            |   /**/                              { []          }

decls       :   decls declAt                      { $2 :: $1  }
            |   /**/                              { []        }

declAt      :   decl                              
                    { DeclAt($1,p())                   }
decl        :   INVARIANT REGISTER registers SEMI
                    { LRegisters (mkRegs Invariant $3) }
            |   INVARIANT /*----*/ registers SEMI
                    { LRegisters (mkRegs Invariant $2) }
            |   /*-----*/ REGISTER registers SEMI
                    { LRegisters (mkRegs Variant   $2) }
            |   /*-----*/ /*----*/ registers SEMI
                    { LRegisters (mkRegs Variant   $1) }
            |   STACKDATA LBRACE data RBRACE
                    { Stackdata(rev $3)                }


registers   :   tyAt regs                   { $1, rev $2 }

regs        :   regs COMMA ID STR           { ($3,Some $4)::$1              }
            |   regs COMMA ID               { ($3,None   )::$1              }
            |   ID STR                      { [($1,Some $2)]                }
            |   ID                          { [($1,None   )]                }

datumAt     :   datum                       { DatumAt($1, p())              }
datum       :   ID COLON                    { Label($1)                     }
            |   ALIGN INT SEMI              { Align(atoi $2)                }
            |   tyAt size initAt SEMI       { MemDecl($1, $2     , Some $3) }
            |   tyAt size        SEMI       { MemDecl($1, $2     , None)    }
            |   tyAt      initAt SEMI       { MemDecl($1, NoSize , Some $2) }
            |   tyAt             SEMI       { MemDecl($1, NoSize , None)    }
                                            

data        :   data  datumAt               { $2 :: $1        }
            |   /**/                        { []              }


initAt      :   init                        { InitAt($1, p()) }
init        :   LBRACE   exprs RBRACE       { InitExprs($2)   }
            |   string                      { InitStr($1)     }
            |   string16                    { InitUStr($1)    }

size        :   LBRACKET exprAt RBRACKET    { FixSize $2      }
            |   LBRACKET       RBRACKET     { DynSize         }

conv        :   FOREIGN STR                 { Some $2         }

aligned     :   ALIGNED INT                 { Some(atoi $2)   }

procedure   :   conv ID frmls body      { let (dec,stmt) = $4 in
                                          Procedure($1  ,$2,$3,dec,stmt) 
                                        }
            |        ID frmls body      { let (dec,stmt) = $3 in
                                          Procedure(None,$1,$2,dec,stmt) 
                                        }


frmls       :   LPAREN  formals RPAREN            { rev $2 }
            |   LPAREN          RPAREN            { []     }
actls       :   LPAREN  actuals RPAREN            { rev $2 }
            |   LPAREN          RPAREN            { []     }

formals     :   formals COMMA formal              { $3 :: $1 }
            |   formal                            { [$1]     }
actuals     :   actuals COMMA actual              { $3 :: $1 }
            |   actual                            { [$1]     }

formal      :   STR INVARIANT tyAt ID     { Some $1, Invariant, $3, $4 }
            |   STR           tyAt ID     { Some $1,   Variant, $2, $3 }
            |       INVARIANT tyAt ID     { None   , Invariant, $2, $3 }
            |                 tyAt ID     { None   ,   Variant, $1, $2 }

actual      :   STR exprAt                        { Some $1, $2 }
            |       exprAt                        { None   , $1 }


flowAt      :   flow                              { FlowAt($1,p())    }
flow        :   ALSO CUTS     TO names            { CutsTo(rev $4)    }
            |   ALSO UNWINDS  TO names            { UnwindsTo(rev $4) }
            |   ALSO RETURNS  TO names            { ReturnsTo(rev $4) }
            |   ALSO ABORTS                       { Aborts            }

flows       :   flows flowAt                      { $2 :: $1 }
            |   /**/                              { []       }

targets     :   TARGETS names                     { rev $2 }
            |   /**/                              { []     }

lvalueAt    :   lvalue                            { LValueAt($1, p())   }
lvalue      :   ID                                { Var($1)             }
            |   tyAt LBRACKET exprAt aligned RBRACKET { Mem($1,$3,$4)   }
            |   tyAt LBRACKET exprAt         RBRACKET { Mem($1,$3,None) }

lvalues     :   lvalues COMMA lvalueAt            { $3 :: $1 }
            |   lvalueAt                          { [$1]     }

tyAt        :   ty                                { TyAt($1,p()) }
ty          :   BITSn                             { BitsTy($1)   }
            |   FLOATn                            { FloatTy($1)  }

body        :   LBRACE decls stmts RBRACE    { rev $2, rev $3 }
block       :   LBRACE       stmts RBRACE    {         rev $2 }

returnto    :   LT sexprAt SLASH sexprAt GT  { Some ($2,$4) }
            |   /**/                         { None         }

stmtAt      :   stmt                         { StmtAt($1,p())           }
stmt        :   SEMI                         { EmptyStmt                }
            |   ID COLON                     { LabelStmt($1)            }
            |   SPAN exprAt exprAt block         { SpanStmt($2,$3,$4)   }
            |   lvalues EQUAL exprs SEMI     { AssignStmt(assign (px()) $1 $3) }

            |   lvalues EQUAL conv PPERCENT ID actls flows SEMI
                        { PrimStmt(          rev $1, $3, $5, $6, $7)          }
            |                 conv PPERCENT ID actls flows SEMI
                        { PrimStmt( []        , $1, $3, $4, $5)               }
            |   lvalues EQUAL conv expr actls targets flows SEMI
                        { CallStmt(          rev $1, $3, $4, $5, $6, $7)      }
            |                 conv expr actls targets flows SEMI
                        { CallStmt( []        , $1, $2, $3, $4, $5)           }
            |   lvalues EQUAL      PPERCENT ID actls flows SEMI
                        { PrimStmt(          rev $1, None, $4, $5, $6)        }
            |                      PPERCENT ID actls flows SEMI
                        { PrimStmt( []        , None, $2, $3, $4)             }
            |   lvalues EQUAL      expr actls targets flows SEMI
                        { CallStmt(          rev $1, None, $3, $4, $5, $6)    }
            |                      expr actls targets flows SEMI
                        { CallStmt( []        , None, $1, $2, $3, $4)         }
            |   IF exprAt block                     { IfStmt($2,$3,[])        }
            |   IF exprAt block ELSE block          { IfStmt($2,$3,$5)        }
            |   GOTO exprAt targets SEMI            { GotoStmt($2,$3)         }
            |   CONTINUATION ID LPAREN names0 RPAREN COLON
                                                  { ContStmt($2,rev $4)       }
            |   CUT TO ID actls flows SEMI        { CutStmt($3,$4, rev $5)    }
            |   conv JUMP exprAt actls targets SEMI { JumpStmt($1  ,$3,$4,$5) }
            |        JUMP exprAt actls targets SEMI { JumpStmt(None,$2,$3,$4) }
            |   conv RETURN returnto actls SEMI   { ReturnStmt($1  ,$3,$4)    }
            |        RETURN returnto actls SEMI   { ReturnStmt(None,$2,$3)    }

stmts       :   stmts stmtAt                     { $2 :: $1 }
            |   /**/                             { []       }

@ Simple expressions [[sexpr]] are a subset of full expressions
[[expr]].  We use them only in the parser but not in the abstract
syntax.  Their only purpose is to provide an [[expr]] subset that does
not include a slash [[/]].  The slash is used by the [[return]]
statement and is bracketed by two expressions which make the whole
thing look like a division expression.  When the expressions are
restricted to [[sexpr]] this ambiguity is gone.

<<parse.mly>>= 

sexprAt     :   sexpr                            { ExprAt($1, p())           }
sexpr       :   INT                              { Int($1, None)             }
            |   INT COLON INT                    { Int($1, Some (atoi $3))   }
            |   FLT                              { Float($1, None)           }
            |   FLT COLON INT                    { Float($1, Some (atoi $3)) }
            |   CHAR                             { Char($1,None)             }
            |   CHAR COLON INT                   { Char($1, Some (atoi $3))  }
            |   lvalueAt                         { Fetch($1)                 }
            |   PERCENT ID actls                 { PrimOp($2, $3)            }

exprAt      :   expr                             { ExprAt($1, p())    }
expr:       |   sexpr                            { $1 }
            |   LPAREN exprAt RPAREN             { $2                 }

            |   exprAt PLUS       exprAt         { BinOp($1,$2,$3)    }
            |   exprAt MINUS      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt PERCENT    exprAt         { BinOp($1,$2,$3)    }
            |   exprAt STAR       exprAt         { BinOp($1,$2,$3)    }
            |   exprAt SLASH      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LLESS      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GGREATER   exprAt         { BinOp($1,$2,$3)    }
            |   exprAt CARET      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt BAR        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt AMPERSAND  exprAt         { BinOp($1,$2,$3)    }
            |   exprAt TILDE      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt EEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt NEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LT         exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GT         exprAt         { BinOp($1,$2,$3)    }

exprs       :   exprs COMMA exprAt               { $3 :: $1 }
            |   exprAt                           { [$1]     }

names       :   names COMMA ID                   { $3 :: $1 }
            |   ID                               { [$1]     }

names0      :   names                            { $1 }
            |   /**/                             { [] }

string      :   STR                              { $1 }
string16    :   UNICODE LPAREN STR RPAREN        { $3 }
@


