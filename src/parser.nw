
% l2h substitution C C--
% l2h substitution asdl ASDL
% l2h substitution ocaml OCaml

% ------------------------------------------------------------------  
\section{Lexical Analysis}\label{sec:scanner}
% ------------------------------------------------------------------  

The scanner for lexical anaylis is generated from a specificaton for
\ocaml~Lex. 

<<scan.mll>>=
(* $Id$ *)

{
    open Error
    open Parse      (* tokens are defined here *)

@ The generated scanner keeps track of its current position in its
input stream by counting the bytes it consumes.  In order to maintain
the more useful information of the current line and column in the
input we maintain some state [[position]] of type [[position]]:

\begin{itemize}
\item [[file]]  is the name of the current input file.
\item [[line]]  is the current line number in [[file]] we are in.
\item [[start]] is the position of the first character in the current line
                in the input stream.  
\item [[tab]]   is an offset in order to keep track of the current
                column in the presence of tab characters.
\end{itemize}

There is one value [[position]] held in the [[Scan]] module which
makes it non-reentrant. It is initialized by [[init]] and
automatically during the initialization of the module.

<<scan.mll>>=
    type position = { mutable file:      string
                    ; mutable start:     int
                    ; mutable line:      int
                    ; mutable tab:       int
                    }

    let position = { file  = "undefined"
                   ; start = 0
                   ; line  = 1
                   ; tab   = 0
                   }

    let init file =
        ( position.file  <- file
        ; position.start <- 0
        ; position.line  <- 1
        ; position.tab   <- 0
        )

@ Whenever the scanner encounters a newline character it updates [[position]]
by calling [[nl]]. The position of the first character of the next line
(the first after the newline) is remembered in [[start]].

<<scan.mll>>= 

    let nl lexbuf =
        ( position.start <- (Lexing.lexeme_start lexbuf) + 1 
        ; position.tab   <- 0
        ; position.line  <- position.line + 1
        )

@ The actual column the scanner is looking is basically the current
position in the input stream minus everything before the actual line.
Tab characters advance the cursor more characters than they are long.
This is honored by adding the [[tab]] value to the value obtained so far.

<<scan.mll>>=
    let column lexbuf =
        Lexing.lexeme_start lexbuf + position.tab - position.start 

@ The tab character is one byte long, but moves the cursor additional
$x$ positions to the right.  The number $x$ of virtual spaces depends
on the column $c$ of the tab:

            $$x = 7 - (c~\textrm{mod}~8)$$ 

Whenever the scanner encounters a tab character it calls the [[tab]]
function to update the [[position.tab]] accordingly.  The first column
is by definition 1 and not zero; this is accounted by the [[pos]]
function, which returns the actual position. 

<<scan.mll>>=
    let tab lexbuf =
        let c  = column lexbuf      in
        ( position.tab <- position.tab + 7 - (c mod 8)
        )
        
    let pos lexbuf =
        ( position.file
        , position.line
        , 1 + column lexbuf  
        )
     
    let lexerror lexbuf msg = 
        let (file, line, col) = pos lexbuf      in
        let m = Printf.sprintf "File %s, line %d, column %d: %s"
                file line col msg
        in 
            error m

@ We define some helpers; [[get]] returns the matched string and is
quite intuitive when called as [[get lexbuf]].

<<scan.mll>>=
    let get         = Lexing.lexeme
    let getchar     = Lexing.lexeme_char
    let strlen      = String.length
    let pos_start   = Lexing.lexeme_start
    let pos_end     = Lexing.lexeme_end

@ Some lexems contain data that we like to extract.  Here is a
substring extraction function (inspired by Python's [[slice]]) that
makes this easy.  The parameters [[start]] and [[stop]] denote which
part of [[str]] should be extracted; negative numbers can be used to
reference the starting point from the end of the string rather than
the beginning.  It is best to think about the [[start]] and [[stop]]
indices as pointing between the characters; some examples makes this
clear:

<<substr example>>=
          h  e  l  l  o  _  w  o  r  l  d
        0  1  2  3  4  5  6  7  8  9  10 11
     -11 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1  0

    substr 0 0 "hello world"            ;; - : string = "hello world"
    substr 0 1 "hello world"            ;; - : string = "h"
    substr 0 (-1) "hello world"         ;; - : string = "hello worl"
    substr (-3) (-1) "hello world"      ;; - : string = "rl"
    substr (0) (3) "hello world"        ;; - : string = "hel"

<<scan.mll>>=
    let substr start stop str = 
        let start = if start <  0 then String.length str + start else start in
        let stop  = if stop  <= 0 then String.length str + stop  else stop  in
            String.sub str start (stop - start)

@ Strings and character literals may contain escaped characters like in
[["this \n"]] example; [[escape]] decodes them.


<<scan.mll>>=
    let escape = function
        | 't'   -> '\t'
        | 'n'   -> '\n'
        | 'b'   -> '\b'
        | 'r'   -> '\r'
        |  x    ->  x  (* default *)

@ All keywords are stored in a hash table that maps them to tokens;
[[keyword s]] tries to lookup [[s]] in the table of keywords and
returns the matching token or raises [[Not_found]]. 

<<scan.mll>>=
    let keywords    = Hashtbl.create 127
    let keyword s   = Hashtbl.find keywords s

    let _ = Array.iter (fun (str,tok) -> Hashtbl.add keywords str tok)
        [|("aborts"         , ABORTS)
        ; ("align"          , ALIGN)
        ; ("aligned"        , ALIGNED)
        ; ("also"           , ALSO)
        ; ("const"          , CONST)
        ; ("continuation"   , CONTINUATION)
        ; ("cut"            , CUT)
        ; ("cuts"           , CUTS)
        ; ("else"           , ELSE)
        ; ("equal"          , EQUAL)
        ; ("export"         , EXPORT)
        ; ("foreign"        , FOREIGN)
        ; ("global"         , GLOBAL)
        ; ("goto"           , GOTO)
        ; ("if"             , IF)
        ; ("import"         , IMPORT)
        ; ("invariant"      , INVARIANT)
        ; ("jump"           , JUMP)
        ; ("pragma"         , PRAGMA)
        ; ("return"         , RETURN)
        ; ("returns"        , RETURNS)
        ; ("section"        , SECTION)
        ; ("semi"           , SEMI)
        ; ("span"           , SPAN)
        ; ("stackdata"      , STACKDATA)
        ; ("targets"        , TARGETS)
        ; ("to"             , TO)
        ; ("unicode"        , UNICODE)
        ; ("unwinds"        , UNWINDS)

        (* pragmas *)

        ; ("line"           , LINE)
        |]

} (* end of prolog *)

@
% ------------------------------------------------------------------  
\subsection{Declarations for Regular Expressions}
% ------------------------------------------------------------------  
<<scan.mll>>=

let digit       = ['0'-'9']
let octal       = ['0'-'7']
let decchar     = digit digit digit

let printable   = [' '-'~']     (* add 8bit chars *)
let alpha       = ['a'-'z' 'A'-'Z' '_']

let escape      = ['\\' '\'' '"' 'n' 't' 'b' 'r']

let sign        = ['+' '-']
let nat         = digit+
let frac        = nat? '.' nat
let exp         = ['e''E'] sign? nat
let float       = frac exp? 
                | nat exp


let id          = alpha (alpha | digit | '.')*
let ws          = [' ' '\b']
let nl          = '\n'
let tab         = '\t'
let flag        = '{' alpha+ '}' 

@
% ------------------------------------------------------------------  
\subsection{The Main Lexer}
% ------------------------------------------------------------------  
<<scan.mll>>=

rule token = parse
    eof         { EOF          }
  | ws+         { token lexbuf }
  | tab         { tab lexbuf; token lexbuf }
  | nl          { nl lexbuf; token lexbuf }

  | ";"         { SEMI         }
  | ":"         { COLON        }
  | ","         { COMMA        }

  | "("         { LPAREN       }
  | ")"         { RPAREN       }
  | "{"         { LBRACE       }
  | "}"         { RBRACE       }
  | "["         { LBRACKET     }
  | "]"         { RBRACKET     }
  | "%%"        { PPERCENT     }

  | "="         { EQUAL        }
  

  (* infix/prefix operators *)
  
  | "+"         { PLUS(get lexbuf)      }
  | "-"         { MINUS(get lexbuf)     }
  | "*"         { STAR(get lexbuf)      }
  | "/"         { SLASH(get lexbuf)     }
  | "%"         { PERCENT(get lexbuf)   }
  | ">>"        { GGREATER(get lexbuf)  }
  | "<<"        { LLESS(get lexbuf)     }
  | "&"         { AMPERSAND(get lexbuf) }
  | "|"         { BAR(get lexbuf)       }
  | "^"         { CARET(get lexbuf)     }
  | "~"         { TILDE(get lexbuf)     }
  | "=="        { EEQ(get lexbuf)       }
  | "!="        { NEQ(get lexbuf)       }
  | "<"         { LT(get lexbuf)        }
  | "<="        { LEQ(get lexbuf)       }
  | ">"         { GT(get lexbuf)        }
  | ">="        { GEQ(get lexbuf)       }

              
  | "bits" nat  { let s = substr 4 0 (get lexbuf) in
                  BITSn (int_of_string s)
                }
  | "float" nat { let s = substr 5 0 (get lexbuf) in
                  FLOATn (int_of_string s)
                }
  | id          { let s  = get lexbuf in 
                  let k  = try keyword s with Not_found -> ID s in
                    if k = PRAGMA then pragma1 lexbuf else k  
                } 
  (*
  | float       { FLT (float_of_string (get lexbuf)) }
  *)
  
  | float       { FLT (get lexbuf) }
  | nat         { INT (int_of_string (get lexbuf))     }


  
  | "/*"        { comment lexbuf 0 }
  | "\""        { string lexbuf (Buffer.create 80) }
  | "'"         { character lexbuf } 
 
  | _                           { lexerror lexbuf "illegal character" }

@
% ------------------------------------------------------------------  
\subsection{Character Literals}
% ------------------------------------------------------------------  
<<scan.mll>>=

and character = parse
    printable      "'"          { CHAR (get lexbuf) }
  | '\\' escape    "'"          { let c = (getchar lexbuf 2) in
                                  CHAR (String.make 1 (escape c))
                                }
  | '\\' decchar   "'"          { let s = substr 2 (-1) (get lexbuf) in
                                  let c = Char.chr (int_of_string s) in
                                  CHAR  (String.make 1 c)
                                }
  | '\\' _                      { lexerror lexbuf "illegal character escape" }
  | _                           { lexerror lexbuf "illegal character constant" }

@
% ------------------------------------------------------------------  
\subsection{Comments}
% ------------------------------------------------------------------  
<<scan.mll>>=

and comment = parse
    eof                         { fun level ->
                                  lexerror lexbuf "unterminated comment" 
                                }
  | [^ '*' '\n' '\t' '/']+      { fun level ->
                                  comment lexbuf level
                                }
  | nl                          { fun level ->
                                  nl lexbuf; comment lexbuf level 
                                }
  | tab                         { fun level -> 
                                  tab lexbuf; comment lexbuf level
                                }
  | "/*"                        { fun level -> 
                                  comment lexbuf (level+1)
                                }
  | "*"+                        { fun level ->
                                  comment lexbuf level
                                }
  | "*/"                        { fun level ->
                                  if   level = 0 
                                  then token lexbuf
                                  else comment lexbuf (level-1)
                                }
  | _                           { fun level ->
                                  comment lexbuf level 
                                }

@
% ------------------------------------------------------------------  
\subsection{Strings}
% ------------------------------------------------------------------  
<<scan.mll>>=

and string = parse
    eof                         { fun buf -> 
                                  lexerror lexbuf "unterminated string" 
                                }
  | "\""                        { fun buf -> STR (Buffer.contents buf) }
  | [^ '\000'-'\031'
       '\128'-'\255'
       '"' '\\' ]+              { fun buf ->
                                  let s    = get lexbuf              in
                                  ( Buffer.add_string buf s
                                  ; string lexbuf buf
                                  )
                                }
  | '\\' escape                 { fun buf ->
                                  let c    = getchar lexbuf 1       in
                                  let c'   = escape c               in
                                  ( Buffer.add_char buf c'
                                  ; string lexbuf buf
                                  )
                                }
  
  | '\\' decchar                { fun buf ->
                                  let s    = substr 1 0 (get lexbuf    ) in
                                  let c    = Char.chr (int_of_string s ) in
                                  ( Buffer.add_char buf c
                                  ; string lexbuf buf
                                  )
                                }
  | '\\' _                      { fun buf ->
                                  lexerror lexbuf "illegal character escape"
                                }
  | _                           { fun buf ->
                                  lexerror lexbuf "illegal character in string"
                                }

@

% ------------------------------------------------------------------  
\subsection{Pragmas}
% ------------------------------------------------------------------ 

Pragmas are special because the work on the lexical as well as on the
grammatical level: 

\begin{itemize}
\item A \textit{known} pragma is handled like a keyword -- normal
      scanning and parsing resumes.

\item An \textit{unknown} pragma is skipped by the scanner. 
\end{itemize}

The split personality of pragmas leads to a scanner that uses a
sequence of three scanner contexts to simulate some parsing in case an
unknown pragma must be skipped over.

To decide whether a pragma is known we look at its
\textit{target}---the identifier following the [[pragma]] keyword.
While looking for the identifier white space is skipped and special
characters are noticed. It is an error when no identifier is found.

When an identifier is found but it is not in the [[keywords]] table
the pragma must be skipped by the parser.  This requires to find the
body of the pragma that is enclosed by curly brackets.  Looking for
the opening bracket takes place in the [[pragma2]] scanner context.

<<scan.mll>>=
 
and pragma1 = parse
    eof                 { EOF }
  | ws+                 { pragma1 lexbuf }
  | tab                 { tab lexbuf; pragma1 lexbuf }
  | nl                  { nl lexbuf; pragma1 lexbuf } 
  | id                  { let s  = get lexbuf in 
                          try keyword s with Not_found -> pragma2 lexbuf
                        }
  | _                   { lexerror lexbuf "id for pragma expected" }


and pragma2 = parse
    eof                 { lexerror lexbuf "pragma body expected" }
  | ws+                 { pragma2 lexbuf }
  | tab                 { tab lexbuf; pragma2 lexbuf }
  | nl                  { nl lexbuf; pragma2 lexbuf }
  | '{'                 { pragma3 lexbuf 0 }
  | _                   { lexerror lexbuf "pragma body expected" }

@ It is an error when the opening bracket is not found. Once it is
found the body of the pragma is skipped over in context [[pragma3]]. A
body of a pragma must contain legal \C~tokens. We don't have to care
for the details but must consider only the following cases:

\begin{itemize}
\item The curly brackets may nest. So we keep a [[level]] to find the
      matching closing bracket.

\item Brackets inside of strings literals, character literals, and
      comments are not considered. Each of these are handled in their
      own scanner contexts.
\end{itemize}


<<scan.mll>>=

and pragma3 = parse
    eof                         { fun level ->
                                  lexerror lexbuf "unterminated pragma" 
                                }
  | [^ '{' '}'  '\n' '\t' 
       '/' '\'' '"']+           { fun level ->
                                  pragma3 lexbuf level
                                }
  | nl                          { fun level ->
                                  nl lexbuf; pragma3 lexbuf level 
                                }
  | tab                         { fun level -> 
                                  tab lexbuf; pragma3 lexbuf level
                                }
  | '{'                         { fun level -> 
                                  pragma3 lexbuf (level+1)
                                }
  | '}'                         { fun level ->
                                  if   level = 0 
                                  then token lexbuf
                                  else pragma3 lexbuf (level-1)
                                }
  | "/*"                        { fun level -> 
                                  ignore (comment lexbuf 0)
                                ; pragma3 lexbuf level
                                }
  | "\""                        { fun level -> 
                                  ignore (string lexbuf (Buffer.create 80))
                                ; pragma3 lexbuf level
                                }
  | "'"                         { fun level -> 
                                  ignore (character lexbuf)
                                ; pragma3 lexbuf level
                                }
  
  | _                           { fun level ->
                                  pragma3 lexbuf level 
                                }
@

% ------------------------------------------------------------------  
\subsection{Debugging the Scanner}
% ------------------------------------------------------------------  

In case of an parse error the problem may be actually caused by the
scanner.  For debugging we define a function [[tok2str]] that turns a
token (as defined in [[parse.mli]]) into a string.  This is used in
the [[Main]] module to define a function that reports the stream of
all tokens for a file together with their positions.

<<scan.mll>>=

{

    let tok2str = function

    | ABORTS            -> "ABORTS"
    | ALIGN             -> "ALIGN"
    | ALIGNED           -> "ALIGNED"
    | ALSO              -> "ALSO"
    | COLON             -> "COLON"
    | COMMA             -> "COMMA"
    | CONST             -> "CONST"
    | CONTINUATION      -> "CONTINUATION"
    | CUT               -> "CUT"
    | CUTS              -> "CUTS"
    | ELSE              -> "ELSE"
    | EOF               -> "EOF"
    | EQUAL             -> "EQUAL"
    | EXPORT            -> "EXPORT"
    | FOREIGN           -> "FOREIGN"
    | GLOBAL            -> "GLOBAL"
    | GOTO              -> "GOTO"
    | IF                -> "IF"
    | IMPORT            -> "IMPORT"
    | INVARIANT         -> "INVARIANT"
    | JUMP              -> "JUMP"
    | LBRACE            -> "LBRACE"
    | LBRACKET          -> "LBRACKET"
    | LPAREN            -> "LPAREN"
    | PPERCENT          -> "PPERCENT"
    | PRAGMA            -> "PRAGMA"
    | RBRACE            -> "RBRACE"
    | RBRACKET          -> "RBRACKET"
    | RETURN            -> "RETURN"
    | RETURNS           -> "RETURNS"
    | RPAREN            -> "RPAREN"
    | SECTION           -> "SECTION"
    | SEMI              -> "SEMI"
    | SPAN              -> "SPAN"
    | STACKDATA         -> "STACKDATA"
    | TARGETS           -> "TARGETS"
    | TO                -> "TO"
    | UNICODE           -> "UNICODE"
    | UNWINDS           -> "UNWINDS"

    (* pragmas *)

    | LINE              -> "LINE"

    | AMPERSAND(s)      -> "AMPERSAND (" ^ s ^ ")"
    | BAR(s)            -> "BAR       (" ^ s ^ ")"
    | CARET(s)          -> "CARET     (" ^ s ^ ")"
    | EEQ(s)            -> "EEQ       (" ^ s ^ ")"
    | GEQ(s)            -> "GEQ       (" ^ s ^ ")"
    | GGREATER(s)       -> "GGREATER  (" ^ s ^ ")"
    | GT(s)             -> "GT        (" ^ s ^ ")"
    | LEQ(s)            -> "LEQ       (" ^ s ^ ")"
    | LLESS(s)          -> "LLESS     (" ^ s ^ ")"
    | LT(s)             -> "LT        (" ^ s ^ ")"
    | MINUS(s)          -> "MINUS     (" ^ s ^ ")"
    | NEQ(s)            -> "NEQ       (" ^ s ^ ")"
    | PERCENT(s)        -> "PERCENT   (" ^ s ^ ")"
    | PLUS(s)           -> "PLUS      (" ^ s ^ ")"
    | SLASH(s)          -> "SLASH     (" ^ s ^ ")"
    | STAR(s)           -> "STAR      (" ^ s ^ ")"
    | TILDE(s)          -> "TILDE     (" ^ s ^ ")"
    
    | ID(s)             -> "ID      (" ^ s               ^ ")"
    | STR(s)            -> "STR     (" ^ s               ^ ")"
    | INT(i)            -> "INT     (" ^ string_of_int i ^ ")"
    | FLT(f)            -> "FLT     (" ^ f               ^ ")"
    | BITSn(i)          -> "BITSn   (" ^ string_of_int i ^ ")"
    | FLOATn(i)         -> "FLOATSn (" ^ string_of_int i ^ ")"
    | CHAR(c)           -> "CHAR    (" ^ c               ^ ")"
    
}

@


% ------------------------------------------------------------------  
\section{Grammatical Analysis}\label{sec:parser}
% ------------------------------------------------------------------  

The parser reads a token stream created by the scanner (module
[[Scan]]) and return the abstract syntax of the input, as defined by
module [[Ast]]. 

<<parse.mly>>=
/* Do not edit; edit $RCSfile$ insted.  */

%{

open Error
open Ast
open List

let parse_error = error

let localReg region = function
    | (var,ty,id,None) -> DeclAt(Register(var,ty,id),region)
    | (var,ty,id,_)    -> parse_error "no hint allowed for local variable"

@ Multiple assignments are defined as a list of pairs in the abstract syntax
but two lists in the concrete syntax. The [[assign]] function implements
the classic [[zip]] function to join them into a list of pairs.

<<parse.mly>>= 

let assign left right = 
    let rec loop = function 
        | [], []            -> []
        | [], rr            -> parse_error "too few lvalues in assignment"
        | ll, []            -> parse_error "too many lvalues in assignment"
        | (l::ll),(r::rr)   -> (l,r)::loop (ll,rr) 
    in
        loop (left,right)
     
@ [[p]] returns the region for the left hand symbol in the current
production.  A region (of type [[int * int]] contains the position of
the first character character of the symbol in input stream, and the
position of the first character after the symbol. These regions are
attached to important nodes in the abstract syntax. The function
[[pn]] returns the region for symbol [[n]] on the right hand side,
where the leftmost symbol has index 1.

<<parse.mly>>=

let p  () = (Parsing.symbol_start (), Parsing.symbol_end())
let pn n  = (Parsing.rhs_start n, Parsing.rhs_end n)

%}

/* keywords, symbols, flags */

%token ABORTS
%token ALIGN
%token ALIGNED
%token ALSO
%token AMPERSAND
%token COLON
%token COMMA
%token CONST
%token CONTINUATION
%token CUT
%token CUTS
%token ELSE
%token EOF
%token EQUAL
%token EXPORT
%token FOREIGN
%token GLOBAL
%token GOTO
%token IF
%token IMPORT
%token INVARIANT
%token JUMP
%token LBRACE
%token LBRACKET
%token LPAREN
%token PPERCENT
%token PRAGMA
%token RBRACE
%token RBRACKET
%token RETURN
%token RETURNS
%token RPAREN
%token SECTION
%token SEMI
%token SPAN
%token STACKDATA
%token TARGETS
%token TO
%token UNICODE
%token UNWINDS

/* pragmas */

%token LINE

/* infix and prefix operators */

%token <string> EEQ NEQ LT LEQ GT GEQ
%token <string> BAR                      
%token <string> CARET                    
%token <string> AMPERSAND                
%token <string> LLESS GGREATER           
%token <string> PLUS MINUS               
%token <string> PERCENT STAR SLASH       
%token <string> TILDE                    


@ The abstract syntax is defined by an \asdl~specification which does not
provide data types for characters and floating point numbers. For this
reason strings are used to capture the values of the respective literals.

<<parse.mly>>=

%token <string> ID
%token <int>    INT
%token <string> FLT
%token <string> CHAR
%token <string> STR
%token <int>    BITSn
%token <int>    FLOATn

/* precedence - from lowest to highest precedence */

%nonassoc   EEQ NEQ LT LEQ GT GEQ
%left       BAR                      
%left       CARET                    
%left       AMPERSAND                
%left       LLESS GGREATER           
%left       PLUS MINUS               
%left       PERCENT STAR SLASH       
%right      TILDE                    

%start program
%type <Ast.program>program

%%

program     :   toplevels                         { rev $1 }

toplevels   :   toplevels toplevelAt              { $2::$1 }
            |   /**/                              { []     }

pragma      :   LINE LBRACE INT RBRACE            { Pragma }
            |   PRAGMA LBRACE RBRACE              { Pragma } 

            
toplevelAt  :   toplevel                          { TopDeclAt($1,p())   }
toplevel    :   IMPORT ty names  SEMI             { Import($2,rev $3)   }
            |   EXPORT    names  SEMI             { Export(rev $2)      }
            |   CONST LBRACE constants RBRACE     { Const(rev $3)       }
            |   GLOBAL LBRACE registers RBRACE    { Global($3)          }
            |   SECTION STR LBRACE sections RBRACE { Section($2,rev $4) }
            |   pragma                            { $1                  }

sections    :   sections sectionAt                { $2 :: $1 }
            |   /**/                              { []       }

sectionAt   :   section                           { SectionAt($1,p()) }
section     :   procedure                         { $1                }
            |   datum                             { Datum($1)         }
            |   span                              { $1                }

span        :   SPAN exprAt expr 
                LBRACE sections RBRACE            { SSpan($2,$3,rev $5) }

constants   :   constants ID EQUAL exprAt SEMI    { ($2,$4)::$1 }
            |   /**/                              { []          }

decls       :   decls declAt                      { $1 @ $2  }
            |   /**/                              { []       }

declAt      :   register                     { map (localReg (p())) $1         }
            |   STACKDATA LBRACE data RBRACE { [DeclAt(Stackdata(rev $3),p())] }

register    :   INVARIANT tyAt regs SEMI 
                { map (fun (id,hint) -> (Invariant,$2,id,hint)) (rev $3) }
            |   /*******/ tyAt regs SEMI       
                { map (fun (id,hint) -> (Variant  ,$1,id,hint)) (rev $2) } 

regs        :   regs COMMA ID STR           { ($3,Some $4)::$1              }
            |   regs COMMA ID               { ($3,None   )::$1              }
            |   ID STR                      { [($1,Some $2)]                }
            |   ID                          { [($1,None   )]                }

registers   :   registers register          { $1 @ $2                       }
            |   /**/                        { []                            }

datumAt     :   datum                       { DatumAt($1, p())              }
datum       :   ID COLON                    { Label($1)                     }
            |   ALIGN INT SEMI              { Align($2)                     }
            |   tyAt size initAt SEMI       { MemDecl($1, $2     , Some $3) }
            |   tyAt size        SEMI       { MemDecl($1, $2     , None)    }
            |   tyAt      initAt SEMI       { MemDecl($1, NoSize , Some $2) }
            |   tyAt             SEMI       { MemDecl($1, NoSize , None)    }
                                            

data        :   data  datumAt               { $2 :: $1        }
            |   /**/                        { []              }


initAt      :   init                        { InitAt($1, p()) }
init        :   LBRACE   exprs RBRACE       { InitExprs($2)   }
            |   string                      { InitStr($1)     }
            |   string16                    { InitUStr($1)    }

size        :   LBRACKET exprAt RBRACKET    { FixSize $2      }
            |   LBRACKET       RBRACKET     { DynSize         }

conv        :   FOREIGN STR                 { Some $2         }

aligned     :   ALIGNED INT                 { Some $2         }

procedure   :   conv ID frmls body      { let (dec,stmt) = $4 in
                                          Procedure($1  ,$2,$3,dec,stmt) 
                                        }
            |        ID frmls body      { let (dec,stmt) = $3 in
                                          Procedure(None,$1,$2,dec,stmt) 
                                        }


frmls       :   LPAREN  formals RPAREN            { rev $2 }
            |   LPAREN          RPAREN            { []     }
actls       :   LPAREN  actuals RPAREN            { rev $2 }
            |   LPAREN          RPAREN            { []     }

formals     :   formals COMMA formal              { $3 :: $1 }
            |   formal                            { [$1]     }
actuals     :   actuals COMMA actual              { $3 :: $1 }
            |   actual                            { [$1]     }

formal      :   STR INVARIANT tyAt ID     { Some $1, Invariant, $3, $4 }
            |   STR           tyAt ID     { Some $1,   Variant, $2, $3 }
            |       INVARIANT tyAt ID     { None   , Invariant, $2, $3 }
            |                 tyAt ID     { None   ,   Variant, $1, $2 }

actual      :   STR expr                          { Some $1, $2 }
            |       expr                          { None   , $1 }


flowAt      :   flow                              { FlowAt($1,p())    }
flow        :   ALSO CUTS     TO names            { CutsTo(rev $4)    }
            |   ALSO UNWINDS  TO names            { UnwindsTo(rev $4) }
            |   ALSO RETURNS  TO names            { ReturnsTo(rev $4) }
            |   ALSO ABORTS                       { Aborts            }

flows       :   flows flowAt                      { $2 :: $1 }
            |   /**/                              { []       }

targets     :   TARGETS names                     { rev $2 }
            |   /**/                              { []     }

lvalueAt    :   lvalue                            { LValueAt($1, p())   }
lvalue      :   ID                                { Var($1)             }
            |   tyAt LBRACKET exprAt aligned RBRACKET { Mem($1,$3,$4)   }
            |   tyAt LBRACKET exprAt         RBRACKET { Mem($1,$3,None) }

lvalues     :   lvalues COMMA lvalueAt            { $3 :: $1 }
            |   lvalueAt                          { [$1]     }

tyAt        :   ty                                { TyAt($1,p()) }
ty          :   BITSn                             { BitsTy($1)   }
            |   FLOATn                            { FloatTy($1)  }

body        :   LBRACE decls stmts RBRACE    { $2, rev $3 }
block       :   LBRACE       stmts RBRACE    {     rev $2 }

returnto    :   LT sexprAt SLASH sexprAt GT  { Some ($2,$4) }
            |   /**/                         { None         }

stmtAt      :   stmt                         { StmtAt($1,p())           }
stmt        :   SEMI                         { EmptyStmt                }
            |   ID COLON                     { LabelStmt($1)            }
            |   SPAN exprAt exprAt block         { SpanStmt($2,$3,$4)   }
            |   lvalues EQUAL exprs SEMI     { AssignStmt(assign $1 $3) }

            |   lvalues EQUAL conv PPERCENT ID actls flows SEMI
                        { PrimStmt(          rev $1, $3, $5, $6, $7)          }
            |                 conv PPERCENT ID actls flows SEMI
                        { PrimStmt( []        , $1, $3, $4, $5)               }
            |   lvalues EQUAL conv expr actls targets flows SEMI
                        { CallStmt(          rev $1, $3, $4, $5, $6, $7)      }
            |                 conv expr actls targets flows SEMI
                        { CallStmt( []        , $1, $2, $3, $4, $5)           }
            |   lvalues EQUAL      PPERCENT ID actls flows SEMI
                        { PrimStmt(          rev $1, None, $4, $5, $6)        }
            |                      PPERCENT ID actls flows SEMI
                        { PrimStmt( []        , None, $2, $3, $4)             }
            |   lvalues EQUAL      expr actls targets flows SEMI
                        { CallStmt(          rev $1, None, $3, $4, $5, $6)    }
            |                      expr actls targets flows SEMI
                        { CallStmt( []        , None, $1, $2, $3, $4)         }
            |   IF exprAt block                     { IfStmt($2,$3,[])        }
            |   IF exprAt block ELSE block          { IfStmt($2,$3,$5)        }
            |   GOTO exprAt targets SEMI            { GotoStmt($2,$3)         }
            |   CONTINUATION ID LPAREN names0 RPAREN COLON
                                                  { ContStmt($2,rev $4)       }
            |   CUT TO ID actls flows SEMI        { CutStmt($3,$4, rev $5)    }
            |   conv JUMP exprAt actls targets SEMI { JumpStmt($1  ,$3,$4,$5) }
            |        JUMP exprAt actls targets SEMI { JumpStmt(None,$2,$3,$4) }
            |   conv RETURN returnto actls SEMI   { ReturnStmt($1  ,$3,$4)    }
            |        RETURN returnto actls SEMI   { ReturnStmt(None,$2,$3)    }

stmts       :   stmts stmtAt                     { $2 :: $1 }
            |   /**/                             { []       }

@ Simple expressions [[sexpr]] are a subset of full expressions
[[expr]].  We use them only in the parser but not in the abstract
syntax.  Their only purpose is to provide an [[expr]] subset that does
not include a slash [[/]].  The slash is used by the [[return]]
statement and is bracketed by two expressions which make the whole
thing look like a division expression.  When the expressions are
restricted to [[sexpr]] this ambiguity is gone.

<<parse.mly>>= 

sexprAt     :   sexpr                            { ExprAt($1, p())    }
sexpr       :   INT                              { Int($1, None)      }
            |   INT COLON INT                    { Int($1, Some $3)   }
            |   FLT                              { Float($1, None)    }
            |   FLT COLON INT                    { Float($1, Some $3) }
            |   CHAR                             { Char($1,None)      }
            |   CHAR COLON INT                   { Char($1, Some $3)  }
            |   lvalueAt                         { Fetch($1)          }
            |   PERCENT ID actls                 { PrimOp($2, $3)     }

exprAt      :   expr                             { ExprAt($1, p())    }
expr:       |   sexpr                            { $1 }
            |   LPAREN exprAt RPAREN             { $2                 }

            |   exprAt PLUS       exprAt         { BinOp($1,$2,$3)    }
            |   exprAt MINUS      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt PERCENT    exprAt         { BinOp($1,$2,$3)    }
            |   exprAt STAR       exprAt         { BinOp($1,$2,$3)    }
            |   exprAt SLASH      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LLESS      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GGREATER   exprAt         { BinOp($1,$2,$3)    }
            |   exprAt CARET      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt BAR        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt AMPERSAND  exprAt         { BinOp($1,$2,$3)    }
            |   exprAt TILDE      exprAt         { BinOp($1,$2,$3)    }
            |   exprAt EEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt NEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LT         exprAt         { BinOp($1,$2,$3)    }
            |   exprAt LEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GEQ        exprAt         { BinOp($1,$2,$3)    }
            |   exprAt GT         exprAt         { BinOp($1,$2,$3)    }

exprs       :   exprs COMMA exprAt               { $3 :: $1 }
            |   exprAt                           { [$1]     }

names       :   names COMMA ID                   { $3 :: $1 }
            |   ID                               { [$1]     }

names0      :   names                            { $1 }
            |   /**/                             { [] }

string      :   STR                              { $1 }
string16    :   UNICODE LPAREN STR RPAREN        { $3 }
@


